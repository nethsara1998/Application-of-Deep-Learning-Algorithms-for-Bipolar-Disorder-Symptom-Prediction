{"cells":[{"cell_type":"markdown","metadata":{"id":"lP6JLo1tGNBg"},"source":["# Artificial Neural Network"]},{"cell_type":"markdown","metadata":{"id":"1E0Q3aoKUCRX"},"source":["## Part 1 - Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"gWZyYmS_UE_L"},"source":["### Importing the libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MxkJoQBkUIHC"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZaTwK7ojXr2F","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1689498622125,"user_tz":-330,"elapsed":23,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"e03f1683-5423-48a1-bac3-b04ae6da8a2a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.12.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}],"source":["tf.__version__"]},{"cell_type":"markdown","metadata":{"id":"cKWAkFVGUU0Z"},"source":["### Importing the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MXUkhkMfU4wq"},"outputs":[],"source":["dataset = pd.read_csv('ymrs_episodes.csv')\n","X = dataset.iloc[:, 1:-1].values\n","y = dataset.iloc[:, -1].values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VYP9cQTWbzuI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689498622126,"user_tz":-330,"elapsed":13,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"e2bdb204-af5f-4816-db66-233df9ac2657"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0 1 0 0 2 2 0 0 0 0 0]\n"," [0 0 0 0 0 2 0 0 0 0 0]\n"," [0 1 0 0 0 2 0 0 2 0 0]\n"," [0 1 0 0 0 2 0 0 2 0 0]\n"," [1 1 0 0 0 2 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0]\n"," [0 2 0 0 2 0 0 0 0 0 0]\n"," [0 0 0 0 2 0 0 0 0 0 0]\n"," [0 0 0 0 2 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 2 0 0 0 2 0 0]\n"," [1 0 0 0 2 2 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 2 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 2 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 2 0 1 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 2 0 0 2 0 0]\n"," [0 0 0 0 2 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0]]\n"]}],"source":["print(X)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"38vKGE6Nb2RR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689498622126,"user_tz":-330,"elapsed":10,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"4da80d33-1957-4a4b-8285-2dd950df3e74"},"outputs":[{"output_type":"stream","name":"stdout","text":["['N' 'N' 'M' 'M' 'N' 'N' 'N' 'N' 'D' 'N' 'D' 'D' 'N' 'N' 'N' 'D' 'N' 'N'\n"," 'M' 'D' 'N' 'D' 'M' 'D' 'M' 'N' 'N' 'M' 'D' 'N' 'N' 'N' 'D' 'N' 'D']\n"]}],"source":["print(y)"]},{"cell_type":"markdown","metadata":{"id":"N6bQ0UgSU-NJ"},"source":["### Encoding categorical data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PxVKWXxLbczC"},"outputs":[],"source":["y= np.array(y.reshape(len(y),1))"]},{"cell_type":"markdown","metadata":{"id":"CUxGZezpbMcb"},"source":["One Hot Encoding the Y column"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AMXC8-KMVirw"},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])])\n","y = np.array(ct.fit_transform(y))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZcxwEon-b8nV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689498622127,"user_tz":-330,"elapsed":9,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"dda4fcff-2314-44bf-dc6b-306695f2da21"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]]\n"]}],"source":["print(y)"]},{"cell_type":"markdown","metadata":{"id":"vHol938cW8zd"},"source":["### Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z-TDt0Y_XEfc"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"]},{"cell_type":"markdown","metadata":{"id":"RE_FcHyfV3TQ"},"source":["### Feature Scaling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ViCrE00rV8Sk"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1OK_PznyHIHT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689498622695,"user_tz":-330,"elapsed":10,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"3f393afa-5f69-475e-dc42-dbe8e5414b45"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[-0.2773501   1.60451491  0.          0.         -0.63245553  1.73205081\n","  -0.19245009  0.          2.44948974  0.          0.        ]\n"," [-0.2773501  -0.43759497  0.          0.          1.58113883 -0.57735027\n","  -0.19245009  0.         -0.40824829  0.          0.        ]\n"," [-0.2773501  -0.43759497  0.          0.          1.58113883 -0.57735027\n","   5.19615242  0.         -0.40824829  0.          0.        ]\n"," [-0.2773501  -0.43759497  0.          0.         -0.63245553 -0.57735027\n","  -0.19245009  0.         -0.40824829  0.          0.        ]\n"," [-0.2773501  -0.43759497  0.          0.         -0.63245553 -0.57735027\n","  -0.19245009  0.         -0.40824829  0.          0.        ]\n"," [-0.2773501  -0.43759497  0.          0.         -0.63245553 -0.57735027\n","  -0.19245009  0.         -0.40824829  0.          0.        ]\n"," [-0.2773501  -0.43759497  0.          0.         -0.63245553 -0.57735027\n","  -0.19245009  0.         -0.40824829  0.          0.        ]\n"," [-0.2773501  -0.43759497  0.          0.         -0.63245553  1.73205081\n","  -0.19245009  0.          2.44948974  0.          0.        ]\n"," [-0.2773501  -0.43759497  0.          0.         -0.63245553 -0.57735027\n","  -0.19245009  0.         -0.40824829  0.          0.        ]\n"," [-0.2773501  -0.43759497  0.          0.         -0.63245553 -0.57735027\n","  -0.19245009  0.         -0.40824829  0.          0.        ]\n"," [-0.2773501  -0.43759497  0.          0.         -0.63245553 -0.57735027\n","  -0.19245009  0.         -0.40824829  0.          0.        ]\n"," [-0.2773501  -0.43759497  0.          0.          1.58113883 -0.57735027\n","  -0.19245009  0.          2.44948974  0.          0.        ]\n"," [-0.2773501  -0.43759497  0.          0.         -0.63245553 -0.57735027\n","  -0.19245009  0.         -0.40824829  0.          0.        ]\n"," [-0.2773501  -0.43759497  0.          0.          1.58113883 -0.57735027\n","  -0.19245009  0.         -0.40824829  0.          0.        ]\n"," [-0.2773501  -0.43759497  0.          0.          1.58113883 -0.57735027\n","  -0.19245009  0.         -0.40824829  0.          0.        ]\n"," [-0.2773501  -0.43759497  0.          0.         -0.63245553  1.73205081\n","  -0.19245009  0.         -0.40824829  0.          0.        ]\n"," [-0.2773501  -0.43759497  0.          0.         -0.63245553 -0.57735027\n","  -0.19245009  0.         -0.40824829  0.          0.        ]\n"," [-0.2773501  -0.43759497  0.          0.         -0.63245553 -0.57735027\n","  -0.19245009  0.         -0.40824829  0.          0.        ]\n"," [-0.2773501  -0.43759497  0.          0.         -0.63245553 -0.57735027\n","  -0.19245009  0.         -0.40824829  0.          0.        ]\n"," [ 3.60555128  1.60451491  0.          0.         -0.63245553  1.73205081\n","  -0.19245009  0.         -0.40824829  0.          0.        ]\n"," [ 3.60555128 -0.43759497  0.          0.          1.58113883  1.73205081\n","  -0.19245009  0.         -0.40824829  0.          0.        ]\n"," [-0.2773501  -0.43759497  0.          0.         -0.63245553 -0.57735027\n","  -0.19245009  0.         -0.40824829  0.          0.        ]\n"," [-0.2773501  -0.43759497  0.          0.         -0.63245553 -0.57735027\n","  -0.19245009  0.         -0.40824829  0.          0.        ]\n"," [-0.2773501   3.64662479  0.          0.          1.58113883 -0.57735027\n","  -0.19245009  0.         -0.40824829  0.          0.        ]\n"," [-0.2773501  -0.43759497  0.          0.         -0.63245553 -0.57735027\n","  -0.19245009  0.         -0.40824829  0.          0.        ]\n"," [-0.2773501  -0.43759497  0.          0.         -0.63245553 -0.57735027\n","  -0.19245009  0.         -0.40824829  0.          0.        ]\n"," [-0.2773501   1.60451491  0.          0.         -0.63245553  1.73205081\n","  -0.19245009  0.          2.44948974  0.          0.        ]\n"," [-0.2773501   1.60451491  0.          0.          1.58113883  1.73205081\n","  -0.19245009  0.         -0.40824829  0.          0.        ]]\n"]}],"source":["print(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mPAGk2yVRyPC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689498622695,"user_tz":-330,"elapsed":8,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"2e9eaee5-fcb8-47fd-8758-17b26b8740bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]]\n"]}],"source":["print(y_train)"]},{"cell_type":"markdown","metadata":{"id":"-zfEzkRVXIwF"},"source":["## Part 2 - Building the ANN"]},{"cell_type":"markdown","metadata":{"id":"KvdeScabXtlB"},"source":["### Initializing the ANN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3dtrScHxXQox"},"outputs":[],"source":["ann = tf.keras.models.Sequential()"]},{"cell_type":"markdown","metadata":{"id":"rP6urV6SX7kS"},"source":["### Adding the input layer and the first hidden layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bppGycBXYCQr"},"outputs":[],"source":["\n","ann.add(tf.keras.layers.Dense(units=81, activation='relu'))"]},{"cell_type":"markdown","metadata":{"id":"BELWAc_8YJze"},"source":["### Adding the second hidden layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YHcQAsy2oATR"},"outputs":[],"source":["ann.add(tf.keras.layers.Dense(units=27, activation='relu'))\n","ann.add(tf.keras.layers.Dense(units=9, activation='relu'))\n"]},{"cell_type":"markdown","metadata":{"id":"OyNEe6RXYcU4"},"source":["### Adding the output layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cn3x41RBYfvY"},"outputs":[],"source":["ann.add(tf.keras.layers.Dense(units=3, activation='softmax'))"]},{"cell_type":"markdown","metadata":{"id":"JT4u2S1_Y4WG"},"source":["## Part 3 - Training the ANN"]},{"cell_type":"markdown","metadata":{"id":"8GWlJChhY_ZI"},"source":["### Compiling the ANN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fG3RrwDXZEaS"},"outputs":[],"source":["ann.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"0QR_G5u7ZLSM"},"source":["### Training the ANN on the Training set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nHZ-LKv_ZRb3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689498635963,"user_tz":-330,"elapsed":13272,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"bba546ef-302c-4679-8b06-752590560b18"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","6/6 [==============================] - 3s 10ms/step - loss: 1.0556 - accuracy: 0.5714\n","Epoch 2/200\n","6/6 [==============================] - 0s 7ms/step - loss: 1.0227 - accuracy: 0.5714\n","Epoch 3/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.9945 - accuracy: 0.5714\n","Epoch 4/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.9695 - accuracy: 0.5714\n","Epoch 5/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.9509 - accuracy: 0.5714\n","Epoch 6/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.9319 - accuracy: 0.6071\n","Epoch 7/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.9122 - accuracy: 0.6071\n","Epoch 8/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.8938 - accuracy: 0.6071\n","Epoch 9/200\n","6/6 [==============================] - 0s 11ms/step - loss: 0.8770 - accuracy: 0.6071\n","Epoch 10/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.8621 - accuracy: 0.6429\n","Epoch 11/200\n","6/6 [==============================] - 0s 16ms/step - loss: 0.8485 - accuracy: 0.6429\n","Epoch 12/200\n","6/6 [==============================] - 0s 19ms/step - loss: 0.8347 - accuracy: 0.6429\n","Epoch 13/200\n","6/6 [==============================] - 0s 13ms/step - loss: 0.8229 - accuracy: 0.6429\n","Epoch 14/200\n","6/6 [==============================] - 0s 9ms/step - loss: 0.8108 - accuracy: 0.6429\n","Epoch 15/200\n","6/6 [==============================] - 0s 8ms/step - loss: 0.8003 - accuracy: 0.6429\n","Epoch 16/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.7898 - accuracy: 0.6429\n","Epoch 17/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.7773 - accuracy: 0.6429\n","Epoch 18/200\n","6/6 [==============================] - 0s 13ms/step - loss: 0.7662 - accuracy: 0.6429\n","Epoch 19/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.7561 - accuracy: 0.6429\n","Epoch 20/200\n","6/6 [==============================] - 0s 7ms/step - loss: 0.7470 - accuracy: 0.7143\n","Epoch 21/200\n","6/6 [==============================] - 0s 7ms/step - loss: 0.7360 - accuracy: 0.7143\n","Epoch 22/200\n","6/6 [==============================] - 0s 20ms/step - loss: 0.7277 - accuracy: 0.7143\n","Epoch 23/200\n","6/6 [==============================] - 0s 21ms/step - loss: 0.7186 - accuracy: 0.7143\n","Epoch 24/200\n","6/6 [==============================] - 0s 14ms/step - loss: 0.7077 - accuracy: 0.7143\n","Epoch 25/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.6976 - accuracy: 0.7143\n","Epoch 26/200\n","6/6 [==============================] - 0s 8ms/step - loss: 0.6904 - accuracy: 0.7143\n","Epoch 27/200\n","6/6 [==============================] - 0s 7ms/step - loss: 0.6808 - accuracy: 0.7143\n","Epoch 28/200\n","6/6 [==============================] - 0s 16ms/step - loss: 0.6730 - accuracy: 0.7143\n","Epoch 29/200\n","6/6 [==============================] - 0s 10ms/step - loss: 0.6659 - accuracy: 0.7143\n","Epoch 30/200\n","6/6 [==============================] - 0s 7ms/step - loss: 0.6586 - accuracy: 0.7143\n","Epoch 31/200\n","6/6 [==============================] - 0s 12ms/step - loss: 0.6530 - accuracy: 0.7143\n","Epoch 32/200\n","6/6 [==============================] - 0s 7ms/step - loss: 0.6471 - accuracy: 0.6786\n","Epoch 33/200\n","6/6 [==============================] - 0s 7ms/step - loss: 0.6378 - accuracy: 0.7143\n","Epoch 34/200\n","6/6 [==============================] - 0s 7ms/step - loss: 0.6331 - accuracy: 0.7143\n","Epoch 35/200\n","6/6 [==============================] - 0s 7ms/step - loss: 0.6275 - accuracy: 0.7143\n","Epoch 36/200\n","6/6 [==============================] - 0s 11ms/step - loss: 0.6230 - accuracy: 0.7143\n","Epoch 37/200\n","6/6 [==============================] - 0s 8ms/step - loss: 0.6168 - accuracy: 0.7143\n","Epoch 38/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.6122 - accuracy: 0.7143\n","Epoch 39/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.6064 - accuracy: 0.7143\n","Epoch 40/200\n","6/6 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.7143\n","Epoch 41/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.6002 - accuracy: 0.7143\n","Epoch 42/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.7143\n","Epoch 43/200\n","6/6 [==============================] - 0s 3ms/step - loss: 0.5924 - accuracy: 0.7143\n","Epoch 44/200\n","6/6 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.7143\n","Epoch 45/200\n","6/6 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.7143\n","Epoch 46/200\n","6/6 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.7143\n","Epoch 47/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.5792 - accuracy: 0.7143\n","Epoch 48/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.5759 - accuracy: 0.7143\n","Epoch 49/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5734 - accuracy: 0.7143\n","Epoch 50/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.6786\n","Epoch 51/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5691 - accuracy: 0.6786\n","Epoch 52/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.5669 - accuracy: 0.6786\n","Epoch 53/200\n","6/6 [==============================] - 0s 3ms/step - loss: 0.5643 - accuracy: 0.7143\n","Epoch 54/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.5612 - accuracy: 0.7143\n","Epoch 55/200\n","6/6 [==============================] - 0s 3ms/step - loss: 0.5599 - accuracy: 0.7143\n","Epoch 56/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.7143\n","Epoch 57/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.7143\n","Epoch 58/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.7143\n","Epoch 59/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.7143\n","Epoch 60/200\n","6/6 [==============================] - 0s 7ms/step - loss: 0.5499 - accuracy: 0.7143\n","Epoch 61/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5495 - accuracy: 0.7143\n","Epoch 62/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5477 - accuracy: 0.7143\n","Epoch 63/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.5452 - accuracy: 0.7143\n","Epoch 64/200\n","6/6 [==============================] - 0s 7ms/step - loss: 0.5440 - accuracy: 0.7143\n","Epoch 65/200\n","6/6 [==============================] - 0s 7ms/step - loss: 0.5419 - accuracy: 0.7143\n","Epoch 66/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.5401 - accuracy: 0.7143\n","Epoch 67/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5395 - accuracy: 0.7143\n","Epoch 68/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5384 - accuracy: 0.7143\n","Epoch 69/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.5358 - accuracy: 0.7143\n","Epoch 70/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7143\n","Epoch 71/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5369 - accuracy: 0.7143\n","Epoch 72/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5346 - accuracy: 0.7143\n","Epoch 73/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5312 - accuracy: 0.7143\n","Epoch 74/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5308 - accuracy: 0.7143\n","Epoch 75/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5307 - accuracy: 0.7143\n","Epoch 76/200\n","6/6 [==============================] - 0s 7ms/step - loss: 0.5274 - accuracy: 0.7143\n","Epoch 77/200\n","6/6 [==============================] - 0s 7ms/step - loss: 0.5269 - accuracy: 0.7143\n","Epoch 78/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5269 - accuracy: 0.7143\n","Epoch 79/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5243 - accuracy: 0.7143\n","Epoch 80/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.5247 - accuracy: 0.7143\n","Epoch 81/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5213 - accuracy: 0.7143\n","Epoch 82/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5230 - accuracy: 0.6786\n","Epoch 83/200\n","6/6 [==============================] - 0s 8ms/step - loss: 0.5213 - accuracy: 0.6786\n","Epoch 84/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5196 - accuracy: 0.7143\n","Epoch 85/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5171 - accuracy: 0.7143\n","Epoch 86/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5167 - accuracy: 0.7143\n","Epoch 87/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5153 - accuracy: 0.7143\n","Epoch 88/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.5173 - accuracy: 0.7143\n","Epoch 89/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.5153 - accuracy: 0.7143\n","Epoch 90/200\n","6/6 [==============================] - 0s 7ms/step - loss: 0.5145 - accuracy: 0.7143\n","Epoch 91/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5130 - accuracy: 0.7143\n","Epoch 92/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.5123 - accuracy: 0.6786\n","Epoch 93/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.5099 - accuracy: 0.7143\n","Epoch 94/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.5093 - accuracy: 0.7143\n","Epoch 95/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5098 - accuracy: 0.7143\n","Epoch 96/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7143\n","Epoch 97/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7143\n","Epoch 98/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5081 - accuracy: 0.7143\n","Epoch 99/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7143\n","Epoch 100/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.5055 - accuracy: 0.7143\n","Epoch 101/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5050 - accuracy: 0.7143\n","Epoch 102/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5038 - accuracy: 0.7143\n","Epoch 103/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5028 - accuracy: 0.7143\n","Epoch 104/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7143\n","Epoch 105/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5028 - accuracy: 0.7143\n","Epoch 106/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.6786\n","Epoch 107/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.6786\n","Epoch 108/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5003 - accuracy: 0.7143\n","Epoch 109/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5001 - accuracy: 0.7143\n","Epoch 110/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7143\n","Epoch 111/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7143\n","Epoch 112/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7143\n","Epoch 113/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4997 - accuracy: 0.7143\n","Epoch 114/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4983 - accuracy: 0.7143\n","Epoch 115/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.4967 - accuracy: 0.7143\n","Epoch 116/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.4963 - accuracy: 0.6786\n","Epoch 117/200\n","6/6 [==============================] - 0s 7ms/step - loss: 0.4963 - accuracy: 0.7143\n","Epoch 118/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.4967 - accuracy: 0.7143\n","Epoch 119/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.4953 - accuracy: 0.7143\n","Epoch 120/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4951 - accuracy: 0.7143\n","Epoch 121/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4976 - accuracy: 0.7143\n","Epoch 122/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4947 - accuracy: 0.7143\n","Epoch 123/200\n","6/6 [==============================] - 0s 8ms/step - loss: 0.4939 - accuracy: 0.7143\n","Epoch 124/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.4944 - accuracy: 0.7143\n","Epoch 125/200\n","6/6 [==============================] - 0s 7ms/step - loss: 0.4919 - accuracy: 0.7143\n","Epoch 126/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.4918 - accuracy: 0.7143\n","Epoch 127/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.4920 - accuracy: 0.7143\n","Epoch 128/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4914 - accuracy: 0.7143\n","Epoch 129/200\n","6/6 [==============================] - 0s 7ms/step - loss: 0.4928 - accuracy: 0.7143\n","Epoch 130/200\n","6/6 [==============================] - 0s 7ms/step - loss: 0.4906 - accuracy: 0.7143\n","Epoch 131/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4938 - accuracy: 0.7143\n","Epoch 132/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.4915 - accuracy: 0.7143\n","Epoch 133/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.4896 - accuracy: 0.6786\n","Epoch 134/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4898 - accuracy: 0.7143\n","Epoch 135/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7143\n","Epoch 136/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.7143\n","Epoch 137/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7143\n","Epoch 138/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.7143\n","Epoch 139/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.6786\n","Epoch 140/200\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7143\n","Epoch 141/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4890 - accuracy: 0.7143\n","Epoch 142/200\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7143\n","Epoch 143/200\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.7143\n","Epoch 144/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4874 - accuracy: 0.7143\n","Epoch 145/200\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7143\n","Epoch 146/200\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.7143\n","Epoch 147/200\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7143\n","Epoch 148/200\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7143\n","Epoch 149/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7143\n","Epoch 150/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.6786\n","Epoch 151/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.6786\n","Epoch 152/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4865 - accuracy: 0.7143\n","Epoch 153/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4881 - accuracy: 0.7143\n","Epoch 154/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.7143\n","Epoch 155/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.4877 - accuracy: 0.7143\n","Epoch 156/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4868 - accuracy: 0.6786\n","Epoch 157/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7143\n","Epoch 158/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7143\n","Epoch 159/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7143\n","Epoch 160/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7143\n","Epoch 161/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4864 - accuracy: 0.6786\n","Epoch 162/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.6786\n","Epoch 163/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.6786\n","Epoch 164/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7143\n","Epoch 165/200\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7143\n","Epoch 166/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.4850 - accuracy: 0.7143\n","Epoch 167/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4858 - accuracy: 0.7143\n","Epoch 168/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7143\n","Epoch 169/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4850 - accuracy: 0.6786\n","Epoch 170/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.4849 - accuracy: 0.7143\n","Epoch 171/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.4839 - accuracy: 0.7143\n","Epoch 172/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.4840 - accuracy: 0.7143\n","Epoch 173/200\n","6/6 [==============================] - 0s 7ms/step - loss: 0.4831 - accuracy: 0.7143\n","Epoch 174/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.6786\n","Epoch 175/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.4835 - accuracy: 0.7143\n","Epoch 176/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4836 - accuracy: 0.7143\n","Epoch 177/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7143\n","Epoch 178/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.4864 - accuracy: 0.7143\n","Epoch 179/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4887 - accuracy: 0.7143\n","Epoch 180/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7143\n","Epoch 181/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.7143\n","Epoch 182/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4835 - accuracy: 0.7143\n","Epoch 183/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.4843 - accuracy: 0.7143\n","Epoch 184/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.6786\n","Epoch 185/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.4854 - accuracy: 0.6786\n","Epoch 186/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7143\n","Epoch 187/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.4844 - accuracy: 0.6786\n","Epoch 188/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4833 - accuracy: 0.6786\n","Epoch 189/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4828 - accuracy: 0.7143\n","Epoch 190/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.4839 - accuracy: 0.7143\n","Epoch 191/200\n","6/6 [==============================] - 0s 6ms/step - loss: 0.4849 - accuracy: 0.7143\n","Epoch 192/200\n","6/6 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7143\n","Epoch 193/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7143\n","Epoch 194/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.7143\n","Epoch 195/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7143\n","Epoch 196/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7143\n","Epoch 197/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.7143\n","Epoch 198/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7143\n","Epoch 199/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7143\n","Epoch 200/200\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.7143\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f473f1daa70>"]},"metadata":{},"execution_count":18}],"source":["ann.fit(X_train, y_train, batch_size = 5, epochs = 200)"]},{"cell_type":"markdown","metadata":{"id":"tJj5k2MxZga3"},"source":["## Part 4 - Making the predictions and evaluating the model"]},{"cell_type":"markdown","metadata":{"id":"u7yx47jPZt11"},"source":["### Predicting the Test set results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nIyEeQdRZwgs","executionInfo":{"status":"ok","timestamp":1689498636539,"user_tz":-330,"elapsed":579,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"00536ac4-6082-4e67-aced-b10d180d4671"},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 124ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]}],"source":["ytest_pred = ann.predict(X_test)\n","ytrain_pred = ann.predict(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Up3Id9FamJCh"},"outputs":[],"source":["y_test_predRounded= []\n","y_test_predEncoded = []\n","ytrain_pred= []\n","ytrain_predRoundeded = []\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hn9vPnXaRRZE"},"outputs":[],"source":["def round(predicted,rounded):\n","  for i in range(len(predicted)):\n","    if predicted[i,0] >  predicted[i,1] and predicted[i,0] >  predicted[i,2]:\n","      rounded.append([1.,0.,0.])\n","    elif predicted[i,1] >  predicted[i,0] and predicted[i,1] >  predicted[i,2]:\n","      rounded.append([0.,1.,0.])\n","    elif predicted[i,2] >  predicted[i,0] and predicted[i,2] >  predicted[i,1]:\n","      rounded.append([0.,0.,1.])\n","    else:\n","      rounded.append([0.,0.,1.])\n","\n","def encode(predicted,encoded):\n","  for i in range(len(predicted)):\n","    if predicted[i,0] >  predicted[i,1] and predicted[i,0] >  predicted[i,2]:\n","      encoded.append(['D'])\n","    elif predicted[i,1] >  predicted[i,0] and predicted[i,1] >  predicted[i,2]:\n","      encoded.append(['M'])\n","    elif predicted[i,2] >  predicted[i,0] and predicted[i,2] >  predicted[i,1]:\n","      encoded.append(['N'])\n","    else:\n","      encoded.append(['N'])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c9-iXheDqeYQ"},"outputs":[],"source":["round(ytest_pred,y_test_predRounded)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xKiFnOVEkVLN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689498636540,"user_tz":-330,"elapsed":8,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"f768a8dc-9da9-4fdf-ff2e-62f996fda7a4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5714285714285714"]},"metadata":{},"execution_count":23}],"source":["from sklearn.metrics import accuracy_score\n","accuracy_score(y_test, y_test_predRounded)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aIA9wlFu1Szx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689498636541,"user_tz":-330,"elapsed":8,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"addb4d6e-48e5-4a06-d444-f4bf67bb5341"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4928571428571428"]},"metadata":{},"execution_count":24}],"source":["from sklearn.metrics import f1_score\n","f1_score(y_test, y_test_predRounded, average='weighted')"]}],"metadata":{"colab":{"provenance":[{"file_id":"1C29XcV-ykBUe9MVmlwPBBbh4IGtA-p9y","timestamp":1634686939845}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}