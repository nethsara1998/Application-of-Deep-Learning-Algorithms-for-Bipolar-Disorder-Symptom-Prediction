{"cells":[{"cell_type":"markdown","metadata":{"id":"lP6JLo1tGNBg"},"source":["# Artificial Neural Network"]},{"cell_type":"markdown","metadata":{"id":"1E0Q3aoKUCRX"},"source":["## Part 1 - Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"gWZyYmS_UE_L"},"source":["### Importing the libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"MxkJoQBkUIHC","executionInfo":{"status":"ok","timestamp":1689497651239,"user_tz":-330,"elapsed":4407,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZaTwK7ojXr2F","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1689497651240,"user_tz":-330,"elapsed":26,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"6ff02721-2886-4ade-f107-c693d10863ee"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.12.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}],"source":["tf.__version__"]},{"cell_type":"markdown","metadata":{"id":"cKWAkFVGUU0Z"},"source":["### Importing the dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"MXUkhkMfU4wq","executionInfo":{"status":"ok","timestamp":1689497651240,"user_tz":-330,"elapsed":22,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}}},"outputs":[],"source":["dataset = pd.read_csv('interviews_episodes.csv')\n","X = dataset.iloc[:, 1:-1].values\n","y = dataset.iloc[:, -1].values"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"VYP9cQTWbzuI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689497651241,"user_tz":-330,"elapsed":23,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"ca95235c-2376-4c9a-e2ec-b231b6e35f72"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[   0    1    1 ...    0   90 1470]\n"," [  -1   -1    2 ...   24  120 1790]\n"," [   0   -1    2 ...   24   90 1545]\n"," ...\n"," [   0    0    1 ...   17   90  300]\n"," [  -1   -1    2 ...   26  120 1710]\n"," [   0   -1    1 ...   25   90 1500]]\n"]}],"source":["print(X)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"38vKGE6Nb2RR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689497651241,"user_tz":-330,"elapsed":20,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"557a1f21-31c8-467e-a2c0-ad1b598680d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'M' 'N' 'N' 'N' 'N' 'N' 'N'\n"," 'N' 'N' 'M' 'M' 'N' 'M' 'N' 'N' 'M' 'M' 'N' 'N' 'N' 'M' 'N' 'N' 'N' 'N'\n"," 'N' 'M' 'M' 'N' 'M' 'N' 'N' 'N' 'N' 'N' 'M' 'N' 'N' 'N' 'M' 'N' 'N' 'M'\n"," 'M' 'N' 'N' 'N' 'M' 'N' 'N' 'N' 'M' 'M' 'N' 'N' 'M' 'N' 'N' 'N' 'M' 'N'\n"," 'N' 'M' 'N' 'N' 'N' 'M' 'M' 'N' 'N' 'M' 'N' 'N' 'N' 'N' 'M' 'D' 'N' 'D'\n"," 'N' 'D' 'D' 'D' 'N' 'N' 'D' 'D' 'N' 'D' 'D' 'N' 'N' 'D' 'D' 'D' 'N' 'N'\n"," 'D' 'D' 'D' 'D' 'N' 'N' 'D' 'D' 'N' 'N' 'D' 'N' 'D' 'D' 'N' 'N' 'N' 'N'\n"," 'N' 'N' 'D' 'N' 'N' 'N' 'D' 'D' 'N' 'D' 'D' 'D' 'N' 'N' 'N' 'D' 'N' 'D'\n"," 'D' 'D' 'D' 'N' 'D' 'N' 'D' 'N' 'D' 'D' 'N' 'D' 'D' 'D' 'N' 'N' 'N' 'D'\n"," 'D' 'D' 'D' 'N' 'D' 'D' 'D' 'D' 'D' 'N' 'N' 'D' 'N' 'D' 'N' 'D' 'N' 'N'\n"," 'N' 'D' 'N' 'D' 'N' 'N' 'D' 'N' 'N' 'N' 'D' 'N' 'D' 'N' 'D' 'N' 'N' 'N'\n"," 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n"," 'N' 'N' 'N' 'D' 'D' 'N' 'N' 'D' 'D' 'N' 'N' 'D' 'N' 'D' 'N' 'N' 'D' 'D'\n"," 'N' 'N' 'N' 'D' 'N' 'N' 'D' 'D' 'N' 'N' 'N' 'N' 'D' 'N' 'D' 'N' 'D' 'N'\n"," 'D' 'N' 'N' 'N' 'N' 'D' 'N' 'D' 'N' 'N' 'D' 'D' 'D' 'N' 'N' 'N' 'D' 'N'\n"," 'D' 'M' 'N' 'D' 'M' 'N' 'N' 'M' 'D' 'N' 'D' 'M' 'M' 'N' 'D' 'N' 'D' 'M'\n"," 'N' 'M' 'N' 'D' 'M' 'M' 'N' 'D' 'M' 'D' 'N' 'M' 'N' 'D' 'N' 'D' 'M' 'N'\n"," 'D' 'M' 'D' 'N' 'D' 'M' 'N' 'M' 'D' 'N' 'D' 'N' 'M' 'M' 'N' 'D' 'N' 'M'\n"," 'D' 'N' 'D' 'M' 'M' 'D' 'N' 'D' 'M' 'D' 'D' 'M' 'D' 'D' 'M' 'D' 'D' 'D'\n"," 'M' 'D' 'D' 'D' 'M' 'D' 'M' 'D' 'D' 'M' 'D' 'D' 'M' 'M' 'D' 'D' 'M' 'D'\n"," 'D' 'D' 'D' 'D' 'M' 'M' 'D' 'D' 'D' 'D' 'M' 'M' 'D' 'D' 'M' 'M' 'N' 'D'\n"," 'D' 'M' 'N' 'N' 'D' 'M' 'N' 'M' 'D' 'D' 'N' 'M' 'N' 'D' 'M' 'M' 'N' 'D'\n"," 'D' 'N' 'M' 'D' 'M' 'N' 'D' 'N' 'M' 'D' 'N' 'M' 'M' 'N' 'D' 'D' 'M' 'N'\n"," 'N' 'D' 'M' 'D' 'N' 'N' 'D' 'M' 'D' 'M' 'D' 'M' 'M' 'N' 'D' 'N' 'D' 'N'\n"," 'D' 'N' 'N' 'N' 'D' 'N' 'D' 'N' 'N' 'N' 'N' 'N' 'D' 'D' 'N' 'N' 'N' 'N'\n"," 'D' 'N' 'N' 'D' 'N' 'D' 'D' 'D' 'N' 'N' 'D' 'N' 'N' 'D' 'N' 'D' 'N' 'N'\n"," 'D' 'N' 'N' 'D' 'N' 'N' 'D' 'N' 'N' 'D' 'N' 'D' 'N' 'N' 'N' 'N' 'D' 'N'\n"," 'N' 'N' 'D' 'N' 'N' 'D' 'N' 'N' 'D' 'N' 'N' 'D' 'D' 'N' 'N' 'D' 'N' 'N'\n"," 'N' 'D' 'N' 'N' 'D' 'D' 'D' 'N' 'N' 'N' 'D' 'N' 'D' 'N' 'N' 'N' 'N' 'N'\n"," 'D' 'N' 'N' 'N' 'D' 'N' 'N' 'D' 'N' 'N' 'N' 'D' 'N' 'D' 'D' 'N' 'N' 'N'\n"," 'N' 'N' 'N' 'D' 'D' 'N' 'N' 'D' 'N' 'D' 'N' 'N' 'N' 'D' 'N' 'N' 'D' 'D'\n"," 'N' 'N' 'D' 'N' 'N' 'D' 'N' 'D' 'N' 'D' 'N' 'D' 'N' 'N' 'N' 'D' 'N' 'D'\n"," 'N' 'D' 'D' 'N' 'N' 'N' 'D' 'D' 'N' 'D' 'N' 'D' 'D' 'D' 'N' 'D' 'D' 'N'\n"," 'N' 'D' 'N' 'D' 'N' 'D' 'N' 'N' 'D' 'N' 'N' 'D' 'N' 'D' 'N' 'N' 'N' 'D'\n"," 'N' 'D' 'N' 'D' 'N' 'N' 'N' 'D' 'N' 'D' 'D' 'N' 'D' 'N' 'D' 'D' 'N' 'D'\n"," 'N' 'N' 'D' 'N' 'D' 'D' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'D' 'N']\n"]}],"source":["print(y)"]},{"cell_type":"markdown","metadata":{"id":"N6bQ0UgSU-NJ"},"source":["### Encoding categorical data"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"PxVKWXxLbczC","executionInfo":{"status":"ok","timestamp":1689497651241,"user_tz":-330,"elapsed":18,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}}},"outputs":[],"source":["y= np.array(y.reshape(len(y),1))"]},{"cell_type":"markdown","metadata":{"id":"CUxGZezpbMcb"},"source":["One Hot Encoding the Y column"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"AMXC8-KMVirw","executionInfo":{"status":"ok","timestamp":1689497651241,"user_tz":-330,"elapsed":18,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}}},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])])\n","y = np.array(ct.fit_transform(y))"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ZcxwEon-b8nV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689497651242,"user_tz":-330,"elapsed":19,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"de042ca0-313f-44b2-eb85-78a9ee3ac4fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," ...\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]]\n"]}],"source":["print(y)"]},{"cell_type":"markdown","metadata":{"id":"vHol938cW8zd"},"source":["### Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Z-TDt0Y_XEfc","executionInfo":{"status":"ok","timestamp":1689497651242,"user_tz":-330,"elapsed":13,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"]},{"cell_type":"markdown","metadata":{"id":"RE_FcHyfV3TQ"},"source":["### Feature Scaling"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"ViCrE00rV8Sk","executionInfo":{"status":"ok","timestamp":1689497651242,"user_tz":-330,"elapsed":12,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}}},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"1OK_PznyHIHT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689497651242,"user_tz":-330,"elapsed":12,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"8d3e8b4d-7fed-4399-b728-0e964fa2e102"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[-0.35725437  0.80699977  0.44180447 ...  1.21397781 -0.15111299\n","   0.2553038 ]\n"," [-0.35725437 -0.18874935  0.44180447 ...  0.59248849  0.44617612\n","   0.29329223]\n"," [-1.33970389 -1.18449847 -0.97690927 ... -1.42735181 -0.15111299\n","   0.0020476 ]\n"," ...\n"," [-0.35725437 -0.18874935  1.86051822 ... -1.42735181 -0.15111299\n","   0.0020476 ]\n"," [ 0.62519515  0.80699977  0.44180447 ...  0.67017466  1.04346522\n","   1.19235175]\n"," [-0.35725437 -0.18874935 -0.97690927 ... -1.42735181 -0.15111299\n","   0.68583935]]\n"]}],"source":["print(X_train)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"mPAGk2yVRyPC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689497651243,"user_tz":-330,"elapsed":11,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"d9ea7f10-0486-4a53-e85a-6bbd21e567c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," ...\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]]\n"]}],"source":["print(y_train)"]},{"cell_type":"markdown","metadata":{"id":"-zfEzkRVXIwF"},"source":["## Part 2 - Building the ANN"]},{"cell_type":"markdown","metadata":{"id":"KvdeScabXtlB"},"source":["### Initializing the ANN"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"3dtrScHxXQox","executionInfo":{"status":"ok","timestamp":1689497651243,"user_tz":-330,"elapsed":10,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}}},"outputs":[],"source":["ann = tf.keras.models.Sequential()"]},{"cell_type":"markdown","metadata":{"id":"rP6urV6SX7kS"},"source":["### Adding the input layer and the first hidden layer"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"bppGycBXYCQr","executionInfo":{"status":"ok","timestamp":1689497651243,"user_tz":-330,"elapsed":10,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}}},"outputs":[],"source":["\n","ann.add(tf.keras.layers.Dense(units=81, activation='relu'))"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"YHcQAsy2oATR","executionInfo":{"status":"ok","timestamp":1689497651816,"user_tz":-330,"elapsed":583,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}}},"outputs":[],"source":["ann.add(tf.keras.layers.Dense(units=27, activation='relu'))\n","ann.add(tf.keras.layers.Dense(units=9, activation='relu'))\n"]},{"cell_type":"markdown","metadata":{"id":"OyNEe6RXYcU4"},"source":["### Adding the output layer"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Cn3x41RBYfvY","executionInfo":{"status":"ok","timestamp":1689497651816,"user_tz":-330,"elapsed":5,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}}},"outputs":[],"source":["ann.add(tf.keras.layers.Dense(units=3, activation='softmax'))"]},{"cell_type":"markdown","metadata":{"id":"JT4u2S1_Y4WG"},"source":["## Part 3 - Training the ANN"]},{"cell_type":"markdown","metadata":{"id":"8GWlJChhY_ZI"},"source":["### Compiling the ANN"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"fG3RrwDXZEaS","executionInfo":{"status":"ok","timestamp":1689497651817,"user_tz":-330,"elapsed":6,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}}},"outputs":[],"source":["ann.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"0QR_G5u7ZLSM"},"source":["### Training the ANN on the Training set"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"nHZ-LKv_ZRb3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689497682248,"user_tz":-330,"elapsed":30436,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"fbc6343d-1a63-4e62-b450-9548514bf9f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","104/104 [==============================] - 1s 2ms/step - loss: 0.9492 - accuracy: 0.6093\n","Epoch 2/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.7060\n","Epoch 3/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.5879 - accuracy: 0.7621\n","Epoch 4/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.5403 - accuracy: 0.7872\n","Epoch 5/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.5081 - accuracy: 0.7756\n","Epoch 6/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.4742 - accuracy: 0.8066\n","Epoch 7/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.8066\n","Epoch 8/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.4417 - accuracy: 0.8201\n","Epoch 9/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.8221\n","Epoch 10/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.4202 - accuracy: 0.8259\n","Epoch 11/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.4008 - accuracy: 0.8375\n","Epoch 12/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.3896 - accuracy: 0.8433\n","Epoch 13/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.3811 - accuracy: 0.8356\n","Epoch 14/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.3731 - accuracy: 0.8375\n","Epoch 15/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.3581 - accuracy: 0.8530\n","Epoch 16/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.3685 - accuracy: 0.8395\n","Epoch 17/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.3456 - accuracy: 0.8569\n","Epoch 18/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.3458 - accuracy: 0.8395\n","Epoch 19/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8665\n","Epoch 20/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8549\n","Epoch 21/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.3189 - accuracy: 0.8549\n","Epoch 22/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.3083 - accuracy: 0.8801\n","Epoch 23/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.3011 - accuracy: 0.8627\n","Epoch 24/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.3040 - accuracy: 0.8762\n","Epoch 25/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2932 - accuracy: 0.8723\n","Epoch 26/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2878 - accuracy: 0.8820\n","Epoch 27/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2875 - accuracy: 0.8839\n","Epoch 28/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2739 - accuracy: 0.8878\n","Epoch 29/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2747 - accuracy: 0.8936\n","Epoch 30/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2680 - accuracy: 0.8859\n","Epoch 31/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2672 - accuracy: 0.9014\n","Epoch 32/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2543 - accuracy: 0.9033\n","Epoch 33/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2656 - accuracy: 0.8917\n","Epoch 34/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.8975\n","Epoch 35/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2511 - accuracy: 0.8917\n","Epoch 36/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.9052\n","Epoch 37/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2450 - accuracy: 0.9033\n","Epoch 38/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2423 - accuracy: 0.9052\n","Epoch 39/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2385 - accuracy: 0.9110\n","Epoch 40/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2345 - accuracy: 0.8994\n","Epoch 41/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2429 - accuracy: 0.9033\n","Epoch 42/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2384 - accuracy: 0.9052\n","Epoch 43/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2249 - accuracy: 0.9052\n","Epoch 44/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2167 - accuracy: 0.9168\n","Epoch 45/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2222 - accuracy: 0.9091\n","Epoch 46/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2195 - accuracy: 0.9072\n","Epoch 47/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2183 - accuracy: 0.9110\n","Epoch 48/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2069 - accuracy: 0.9226\n","Epoch 49/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2107 - accuracy: 0.9130\n","Epoch 50/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2182 - accuracy: 0.9130\n","Epoch 51/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.9168\n","Epoch 52/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2132 - accuracy: 0.9110\n","Epoch 53/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2029 - accuracy: 0.9246\n","Epoch 54/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2015 - accuracy: 0.9265\n","Epoch 55/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9265\n","Epoch 56/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2042 - accuracy: 0.9168\n","Epoch 57/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1990 - accuracy: 0.9207\n","Epoch 58/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1940 - accuracy: 0.9284\n","Epoch 59/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1878 - accuracy: 0.9284\n","Epoch 60/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9149\n","Epoch 61/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1899 - accuracy: 0.9265\n","Epoch 62/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9284\n","Epoch 63/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.9226\n","Epoch 64/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.9246\n","Epoch 65/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9226\n","Epoch 66/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9362\n","Epoch 67/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.1813 - accuracy: 0.9304\n","Epoch 68/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1904 - accuracy: 0.9246\n","Epoch 69/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.9226\n","Epoch 70/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.9207\n","Epoch 71/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.2057 - accuracy: 0.9168\n","Epoch 72/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.9265\n","Epoch 73/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.9342\n","Epoch 74/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.9284\n","Epoch 75/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.9265\n","Epoch 76/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.1877 - accuracy: 0.9149\n","Epoch 77/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1730 - accuracy: 0.9246\n","Epoch 78/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.9284\n","Epoch 79/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.9284\n","Epoch 80/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1666 - accuracy: 0.9304\n","Epoch 81/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1772 - accuracy: 0.9265\n","Epoch 82/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1699 - accuracy: 0.9304\n","Epoch 83/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1726 - accuracy: 0.9284\n","Epoch 84/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1617 - accuracy: 0.9304\n","Epoch 85/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.9168\n","Epoch 86/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.9188\n","Epoch 87/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1684 - accuracy: 0.9226\n","Epoch 88/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1660 - accuracy: 0.9342\n","Epoch 89/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1673 - accuracy: 0.9304\n","Epoch 90/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1538 - accuracy: 0.9342\n","Epoch 91/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1585 - accuracy: 0.9246\n","Epoch 92/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1678 - accuracy: 0.9400\n","Epoch 93/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1583 - accuracy: 0.9265\n","Epoch 94/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1691 - accuracy: 0.9246\n","Epoch 95/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1628 - accuracy: 0.9342\n","Epoch 96/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1650 - accuracy: 0.9265\n","Epoch 97/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1678 - accuracy: 0.9246\n","Epoch 98/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1717 - accuracy: 0.9342\n","Epoch 99/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1584 - accuracy: 0.9304\n","Epoch 100/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1612 - accuracy: 0.9284\n","Epoch 101/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1639 - accuracy: 0.9265\n","Epoch 102/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1654 - accuracy: 0.9304\n","Epoch 103/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1505 - accuracy: 0.9304\n","Epoch 104/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.1546 - accuracy: 0.9246\n","Epoch 105/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1637 - accuracy: 0.9323\n","Epoch 106/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1506 - accuracy: 0.9304\n","Epoch 107/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1531 - accuracy: 0.9323\n","Epoch 108/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1638 - accuracy: 0.9226\n","Epoch 109/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.9420\n","Epoch 110/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1477 - accuracy: 0.9323\n","Epoch 111/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1499 - accuracy: 0.9381\n","Epoch 112/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1508 - accuracy: 0.9304\n","Epoch 113/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1500 - accuracy: 0.9323\n","Epoch 114/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1466 - accuracy: 0.9381\n","Epoch 115/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1497 - accuracy: 0.9246\n","Epoch 116/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1581 - accuracy: 0.9304\n","Epoch 117/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9381\n","Epoch 118/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1588 - accuracy: 0.9323\n","Epoch 119/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1492 - accuracy: 0.9381\n","Epoch 120/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1470 - accuracy: 0.9362\n","Epoch 121/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1510 - accuracy: 0.9246\n","Epoch 122/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1613 - accuracy: 0.9342\n","Epoch 123/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1498 - accuracy: 0.9304\n","Epoch 124/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9304\n","Epoch 125/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1468 - accuracy: 0.9362\n","Epoch 126/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1500 - accuracy: 0.9420\n","Epoch 127/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1501 - accuracy: 0.9342\n","Epoch 128/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1515 - accuracy: 0.9323\n","Epoch 129/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1427 - accuracy: 0.9458\n","Epoch 130/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1496 - accuracy: 0.9362\n","Epoch 131/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1426 - accuracy: 0.9323\n","Epoch 132/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1417 - accuracy: 0.9342\n","Epoch 133/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.9342\n","Epoch 134/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1374 - accuracy: 0.9381\n","Epoch 135/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.9304\n","Epoch 136/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1355 - accuracy: 0.9400\n","Epoch 137/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1505 - accuracy: 0.9342\n","Epoch 138/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1363 - accuracy: 0.9342\n","Epoch 139/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1461 - accuracy: 0.9362\n","Epoch 140/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1448 - accuracy: 0.9284\n","Epoch 141/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1410 - accuracy: 0.9323\n","Epoch 142/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.9400\n","Epoch 143/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1338 - accuracy: 0.9362\n","Epoch 144/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1567 - accuracy: 0.9265\n","Epoch 145/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1314 - accuracy: 0.9458\n","Epoch 146/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.9381\n","Epoch 147/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.9381\n","Epoch 148/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.1375 - accuracy: 0.9439\n","Epoch 149/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.1364 - accuracy: 0.9381\n","Epoch 150/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.9420\n","Epoch 151/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.1286 - accuracy: 0.9458\n","Epoch 152/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.1290 - accuracy: 0.9497\n","Epoch 153/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.1330 - accuracy: 0.9420\n","Epoch 154/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.1288 - accuracy: 0.9381\n","Epoch 155/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.1280 - accuracy: 0.9400\n","Epoch 156/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.1253 - accuracy: 0.9420\n","Epoch 157/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1299 - accuracy: 0.9400\n","Epoch 158/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.9478\n","Epoch 159/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1360 - accuracy: 0.9342\n","Epoch 160/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1244 - accuracy: 0.9478\n","Epoch 161/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1316 - accuracy: 0.9362\n","Epoch 162/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1371 - accuracy: 0.9439\n","Epoch 163/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1645 - accuracy: 0.9323\n","Epoch 164/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1253 - accuracy: 0.9420\n","Epoch 165/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1289 - accuracy: 0.9458\n","Epoch 166/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1239 - accuracy: 0.9439\n","Epoch 167/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1270 - accuracy: 0.9458\n","Epoch 168/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.9555\n","Epoch 169/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1166 - accuracy: 0.9458\n","Epoch 170/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1193 - accuracy: 0.9478\n","Epoch 171/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1232 - accuracy: 0.9458\n","Epoch 172/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1230 - accuracy: 0.9400\n","Epoch 173/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1175 - accuracy: 0.9536\n","Epoch 174/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1164 - accuracy: 0.9458\n","Epoch 175/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.9478\n","Epoch 176/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1174 - accuracy: 0.9497\n","Epoch 177/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1334 - accuracy: 0.9400\n","Epoch 178/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1227 - accuracy: 0.9381\n","Epoch 179/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1143 - accuracy: 0.9536\n","Epoch 180/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.9439\n","Epoch 181/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.9497\n","Epoch 182/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.9420\n","Epoch 183/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.9478\n","Epoch 184/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9439\n","Epoch 185/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.9497\n","Epoch 186/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1121 - accuracy: 0.9439\n","Epoch 187/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1385 - accuracy: 0.9323\n","Epoch 188/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1073 - accuracy: 0.9536\n","Epoch 189/200\n","104/104 [==============================] - 0s 2ms/step - loss: 0.1144 - accuracy: 0.9516\n","Epoch 190/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.9555\n","Epoch 191/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1195 - accuracy: 0.9439\n","Epoch 192/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1203 - accuracy: 0.9497\n","Epoch 193/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1211 - accuracy: 0.9516\n","Epoch 194/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1130 - accuracy: 0.9536\n","Epoch 195/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.9439\n","Epoch 196/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9555\n","Epoch 197/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1205 - accuracy: 0.9516\n","Epoch 198/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1365 - accuracy: 0.9381\n","Epoch 199/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1044 - accuracy: 0.9555\n","Epoch 200/200\n","104/104 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.9497\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ec891c69f60>"]},"metadata":{},"execution_count":18}],"source":["ann.fit(X_train, y_train, batch_size = 5, epochs = 200)"]},{"cell_type":"markdown","metadata":{"id":"tJj5k2MxZga3"},"source":["## Part 4 - Making the predictions and evaluating the model"]},{"cell_type":"markdown","metadata":{"id":"u7yx47jPZt11"},"source":["### Predicting the Test set results"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"nIyEeQdRZwgs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689497682828,"user_tz":-330,"elapsed":587,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"1d88b28d-4393-43ba-8964-7c1f6bae1b46"},"outputs":[{"output_type":"stream","name":"stdout","text":["5/5 [==============================] - 0s 2ms/step\n","17/17 [==============================] - 0s 1ms/step\n"]}],"source":["ytest_pred = ann.predict(X_test)\n","ytrain_pred = ann.predict(X_train)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"Up3Id9FamJCh","executionInfo":{"status":"ok","timestamp":1689497682828,"user_tz":-330,"elapsed":7,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}}},"outputs":[],"source":["y_test_predRounded= []\n","y_test_predEncoded = []\n","ytrain_pred= []\n","ytrain_predRoundeded = []\n"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"hn9vPnXaRRZE","executionInfo":{"status":"ok","timestamp":1689497682829,"user_tz":-330,"elapsed":8,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}}},"outputs":[],"source":["def round(predicted,rounded):\n","  for i in range(len(predicted)):\n","    if predicted[i,0] >  predicted[i,1] and predicted[i,0] >  predicted[i,2]:\n","      rounded.append([1.,0.,0.])\n","    elif predicted[i,1] >  predicted[i,0] and predicted[i,1] >  predicted[i,2]:\n","      rounded.append([0.,1.,0.])\n","    elif predicted[i,2] >  predicted[i,0] and predicted[i,2] >  predicted[i,1]:\n","      rounded.append([0.,0.,1.])\n","    else:\n","      rounded.append([0.,0.,1.])\n","\n","def encode(predicted,encoded):\n","  for i in range(len(predicted)):\n","    if predicted[i,0] >  predicted[i,1] and predicted[i,0] >  predicted[i,2]:\n","      encoded.append(['D'])\n","    elif predicted[i,1] >  predicted[i,0] and predicted[i,1] >  predicted[i,2]:\n","      encoded.append(['M'])\n","    elif predicted[i,2] >  predicted[i,0] and predicted[i,2] >  predicted[i,1]:\n","      encoded.append(['N'])\n","    else:\n","      encoded.append(['N'])\n","\n"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"c9-iXheDqeYQ","executionInfo":{"status":"ok","timestamp":1689497682829,"user_tz":-330,"elapsed":8,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}}},"outputs":[],"source":["round(ytest_pred,y_test_predRounded)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"xKiFnOVEkVLN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689497682829,"user_tz":-330,"elapsed":8,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"e4d17741-753b-40b5-f69b-12bb57095e1e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7461538461538462"]},"metadata":{},"execution_count":23}],"source":["from sklearn.metrics import accuracy_score\n","accuracy_score(y_test, y_test_predRounded)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"aIA9wlFu1Szx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689497682829,"user_tz":-330,"elapsed":5,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"dcebaf19-fb21-4850-bb36-af692457c775"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.749651436039132"]},"metadata":{},"execution_count":24}],"source":["from sklearn.metrics import f1_score\n","f1_score(y_test, y_test_predRounded, average='weighted')"]}],"metadata":{"colab":{"provenance":[{"file_id":"1C29XcV-ykBUe9MVmlwPBBbh4IGtA-p9y","timestamp":1634686939845}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}