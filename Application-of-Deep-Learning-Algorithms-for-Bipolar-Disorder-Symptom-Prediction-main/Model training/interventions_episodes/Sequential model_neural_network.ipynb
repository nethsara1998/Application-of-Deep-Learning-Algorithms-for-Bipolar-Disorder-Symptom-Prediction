{"cells":[{"cell_type":"markdown","metadata":{"id":"lP6JLo1tGNBg"},"source":["# Artificial Neural Network"]},{"cell_type":"markdown","metadata":{"id":"1E0Q3aoKUCRX"},"source":["## Part 1 - Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"gWZyYmS_UE_L"},"source":["### Importing the libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MxkJoQBkUIHC"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZaTwK7ojXr2F","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1689498224078,"user_tz":-330,"elapsed":26,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"e6819f64-9e55-407a-c8bf-57c43163f982"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.12.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}],"source":["tf.__version__"]},{"cell_type":"markdown","metadata":{"id":"cKWAkFVGUU0Z"},"source":["### Importing the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MXUkhkMfU4wq"},"outputs":[],"source":["dataset = pd.read_csv('interventions_episodes.csv')\n","X = dataset.iloc[:, 1:-1].values\n","y = dataset.iloc[:, -1].values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VYP9cQTWbzuI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689498224078,"user_tz":-330,"elapsed":16,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"81bcb22a-9fef-43db-f4f7-c3a52c02d621"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[80  5]\n"," [80  5]\n"," [80  1]\n"," [60  3]\n"," [70  5]\n"," [80  3]\n"," [85  2]\n"," [80  3]\n"," [90  3]\n"," [85  3]\n"," [75  4]\n"," [75  4]\n"," [90  5]\n"," [90  3]\n"," [80  6]\n"," [50  7]\n"," [80  6]\n"," [60  5]\n"," [85  2]\n"," [75  5]\n"," [85  1]\n"," [65  5]\n"," [85  5]\n"," [90  2]\n"," [70  5]\n"," [90  3]\n"," [70  5]\n"," [80  5]\n"," [70  2]\n"," [85  2]\n"," [95  2]\n"," [95  2]\n"," [95  4]\n"," [95  4]\n"," [85  2]\n"," [90  6]\n"," [90  3]\n"," [75  4]\n"," [70  5]\n"," [70  5]\n"," [85  2]\n"," [80  2]\n"," [90  3]\n"," [80  3]\n"," [90  2]\n"," [85  3]\n"," [90  4]\n"," [80  6]\n"," [95  2]\n"," [85  3]\n"," [85  3]\n"," [85  3]\n"," [85  6]\n"," [90  3]\n"," [80  6]\n"," [90  3]\n"," [90  4]\n"," [80  3]\n"," [90  4]]\n"]}],"source":["print(X)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"38vKGE6Nb2RR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689498224079,"user_tz":-330,"elapsed":14,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"34a40ef7-0865-42af-dbd6-c4898d93f6b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["['N' 'N' 'N' 'M' 'N' 'M' 'N' 'N' 'M' 'N' 'N' 'N' 'N' 'N' 'D' 'D' 'D' 'D'\n"," 'N' 'D' 'N' 'N' 'N' 'N' 'D' 'N' 'D' 'N' 'M' 'M' 'N' 'N' 'N' 'N' 'D' 'M'\n"," 'D' 'M' 'D' 'D' 'M' 'M' 'N' 'M' 'N' 'D' 'N' 'M' 'D' 'D' 'N' 'N' 'N' 'D'\n"," 'N' 'D' 'D' 'N' 'N']\n"]}],"source":["print(y)"]},{"cell_type":"markdown","metadata":{"id":"N6bQ0UgSU-NJ"},"source":["### Encoding categorical data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PxVKWXxLbczC"},"outputs":[],"source":["y= np.array(y.reshape(len(y),1))"]},{"cell_type":"markdown","metadata":{"id":"CUxGZezpbMcb"},"source":["One Hot Encoding the Y column"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AMXC8-KMVirw"},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])])\n","y = np.array(ct.fit_transform(y))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZcxwEon-b8nV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689498224079,"user_tz":-330,"elapsed":12,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"8e051d28-c372-4ac7-b02f-739b295bc3b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]]\n"]}],"source":["print(y)"]},{"cell_type":"markdown","metadata":{"id":"vHol938cW8zd"},"source":["### Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z-TDt0Y_XEfc"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"]},{"cell_type":"markdown","metadata":{"id":"RE_FcHyfV3TQ"},"source":["### Feature Scaling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ViCrE00rV8Sk"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1OK_PznyHIHT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689498224080,"user_tz":-330,"elapsed":11,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"d025d450-6cfb-4842-a1cb-cce5e6d183bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 1.26591947 -1.19203991]\n"," [-0.25967579 -1.19203991]\n"," [ 1.26591947  0.20860698]\n"," [ 0.75738771 -0.49171646]\n"," [ 1.26591947 -1.19203991]\n"," [-0.25967579 -0.49171646]\n"," [-0.25967579  1.60925388]\n"," [ 1.26591947  0.20860698]\n"," [ 0.24885596 -0.49171646]\n"," [ 0.24885596 -1.19203991]\n"," [-0.76820754  0.20860698]\n"," [ 0.75738771  0.20860698]\n"," [ 0.24885596 -1.19203991]\n"," [ 0.75738771 -0.49171646]\n"," [-0.25967579  0.90893043]\n"," [-3.3108663   2.30957733]\n"," [-0.25967579 -0.49171646]\n"," [ 1.26591947 -1.19203991]\n"," [-0.25967579  1.60925388]\n"," [ 0.24885596 -0.49171646]\n"," [ 0.24885596 -1.89236336]\n"," [ 0.24885596 -0.49171646]\n"," [ 0.75738771 -0.49171646]\n"," [ 0.75738771 -0.49171646]\n"," [ 0.75738771 -0.49171646]\n"," [-2.29380279  0.90893043]\n"," [ 0.75738771  0.20860698]\n"," [-0.25967579 -0.49171646]\n"," [ 0.24885596  1.60925388]\n"," [-1.27673929  0.90893043]\n"," [-0.25967579  0.90893043]\n"," [ 0.75738771  0.90893043]\n"," [ 0.24885596 -0.49171646]\n"," [-1.27673929  0.90893043]\n"," [ 0.24885596 -1.19203991]\n"," [ 0.75738771 -1.19203991]\n"," [ 0.75738771 -0.49171646]\n"," [-1.78527104  0.90893043]\n"," [-0.76820754  0.90893043]\n"," [ 0.24885596 -0.49171646]\n"," [-1.27673929  0.90893043]\n"," [-0.25967579  1.60925388]\n"," [-2.29380279 -0.49171646]\n"," [-0.25967579  0.90893043]\n"," [ 0.75738771 -0.49171646]\n"," [-0.25967579  1.60925388]\n"," [ 0.75738771 -1.19203991]]\n"]}],"source":["print(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mPAGk2yVRyPC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689498224080,"user_tz":-330,"elapsed":9,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"6bbfe085-2ba2-4cef-c616-9fb2c6608bfb"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]]\n"]}],"source":["print(y_train)"]},{"cell_type":"markdown","metadata":{"id":"-zfEzkRVXIwF"},"source":["## Part 2 - Building the ANN"]},{"cell_type":"markdown","metadata":{"id":"KvdeScabXtlB"},"source":["### Initializing the ANN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3dtrScHxXQox"},"outputs":[],"source":["ann = tf.keras.models.Sequential()"]},{"cell_type":"markdown","metadata":{"id":"rP6urV6SX7kS"},"source":["### Adding the input layer and the first hidden layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bppGycBXYCQr"},"outputs":[],"source":["\n","ann.add(tf.keras.layers.Dense(units=81, activation='relu'))"]},{"cell_type":"markdown","metadata":{"id":"BELWAc_8YJze"},"source":["### Adding the second hidden layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YHcQAsy2oATR"},"outputs":[],"source":["ann.add(tf.keras.layers.Dense(units=27, activation='relu'))\n","ann.add(tf.keras.layers.Dense(units=9, activation='relu'))\n"]},{"cell_type":"markdown","metadata":{"id":"OyNEe6RXYcU4"},"source":["### Adding the output layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cn3x41RBYfvY"},"outputs":[],"source":["ann.add(tf.keras.layers.Dense(units=3, activation='softmax'))"]},{"cell_type":"markdown","metadata":{"id":"JT4u2S1_Y4WG"},"source":["## Part 3 - Training the ANN"]},{"cell_type":"markdown","metadata":{"id":"8GWlJChhY_ZI"},"source":["### Compiling the ANN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fG3RrwDXZEaS"},"outputs":[],"source":["ann.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"0QR_G5u7ZLSM"},"source":["### Training the ANN on the Training set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nHZ-LKv_ZRb3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689498234451,"user_tz":-330,"elapsed":9670,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"c7e28013-6082-42c1-ca69-637cd31547a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","10/10 [==============================] - 1s 3ms/step - loss: 1.0851 - accuracy: 0.3404\n","Epoch 2/200\n","10/10 [==============================] - 0s 3ms/step - loss: 1.0669 - accuracy: 0.4255\n","Epoch 3/200\n","10/10 [==============================] - 0s 2ms/step - loss: 1.0537 - accuracy: 0.5106\n","Epoch 4/200\n","10/10 [==============================] - 0s 2ms/step - loss: 1.0350 - accuracy: 0.5957\n","Epoch 5/200\n","10/10 [==============================] - 0s 3ms/step - loss: 1.0177 - accuracy: 0.5532\n","Epoch 6/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.9992 - accuracy: 0.4681\n","Epoch 7/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.9836 - accuracy: 0.5745\n","Epoch 8/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.9670 - accuracy: 0.5957\n","Epoch 9/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.9506 - accuracy: 0.5957\n","Epoch 10/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.9364 - accuracy: 0.5957\n","Epoch 11/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.9263 - accuracy: 0.5957\n","Epoch 12/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.9166 - accuracy: 0.5957\n","Epoch 13/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.9032 - accuracy: 0.6596\n","Epoch 14/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8949 - accuracy: 0.6596\n","Epoch 15/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8862 - accuracy: 0.6596\n","Epoch 16/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.8816 - accuracy: 0.6383\n","Epoch 17/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.8731 - accuracy: 0.6383\n","Epoch 18/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8705 - accuracy: 0.6383\n","Epoch 19/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8620 - accuracy: 0.6383\n","Epoch 20/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8619 - accuracy: 0.6596\n","Epoch 21/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8558 - accuracy: 0.6596\n","Epoch 22/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8577 - accuracy: 0.6596\n","Epoch 23/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8531 - accuracy: 0.6596\n","Epoch 24/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8487 - accuracy: 0.6809\n","Epoch 25/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.8438 - accuracy: 0.6809\n","Epoch 26/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8396 - accuracy: 0.6809\n","Epoch 27/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8361 - accuracy: 0.6809\n","Epoch 28/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8381 - accuracy: 0.6596\n","Epoch 29/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8353 - accuracy: 0.6596\n","Epoch 30/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8327 - accuracy: 0.6596\n","Epoch 31/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8307 - accuracy: 0.6596\n","Epoch 32/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8283 - accuracy: 0.6809\n","Epoch 33/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8273 - accuracy: 0.6809\n","Epoch 34/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8264 - accuracy: 0.6809\n","Epoch 35/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8249 - accuracy: 0.6809\n","Epoch 36/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8223 - accuracy: 0.6809\n","Epoch 37/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8226 - accuracy: 0.6809\n","Epoch 38/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8202 - accuracy: 0.6809\n","Epoch 39/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8152 - accuracy: 0.6809\n","Epoch 40/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.8206 - accuracy: 0.6809\n","Epoch 41/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8168 - accuracy: 0.6809\n","Epoch 42/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.8154 - accuracy: 0.6809\n","Epoch 43/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8148 - accuracy: 0.6809\n","Epoch 44/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8144 - accuracy: 0.6809\n","Epoch 45/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.8128 - accuracy: 0.6809\n","Epoch 46/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.8112 - accuracy: 0.6809\n","Epoch 47/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.8120 - accuracy: 0.6809\n","Epoch 48/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.8069 - accuracy: 0.6809\n","Epoch 49/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8051 - accuracy: 0.6809\n","Epoch 50/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8051 - accuracy: 0.6809\n","Epoch 51/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8045 - accuracy: 0.6809\n","Epoch 52/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.8021 - accuracy: 0.6809\n","Epoch 53/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.8018 - accuracy: 0.6596\n","Epoch 54/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8015 - accuracy: 0.6596\n","Epoch 55/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7984 - accuracy: 0.7021\n","Epoch 56/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8001 - accuracy: 0.7021\n","Epoch 57/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7970 - accuracy: 0.6809\n","Epoch 58/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7981 - accuracy: 0.6596\n","Epoch 59/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7914 - accuracy: 0.6809\n","Epoch 60/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7959 - accuracy: 0.7021\n","Epoch 61/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7905 - accuracy: 0.7021\n","Epoch 62/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7899 - accuracy: 0.7021\n","Epoch 63/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7908 - accuracy: 0.7234\n","Epoch 64/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7886 - accuracy: 0.7234\n","Epoch 65/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7880 - accuracy: 0.7021\n","Epoch 66/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7861 - accuracy: 0.7021\n","Epoch 67/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7824 - accuracy: 0.7021\n","Epoch 68/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7827 - accuracy: 0.7021\n","Epoch 69/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7833 - accuracy: 0.7021\n","Epoch 70/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7835 - accuracy: 0.7021\n","Epoch 71/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7827 - accuracy: 0.7021\n","Epoch 72/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7773 - accuracy: 0.7021\n","Epoch 73/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7767 - accuracy: 0.7021\n","Epoch 74/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7764 - accuracy: 0.6809\n","Epoch 75/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7780 - accuracy: 0.6596\n","Epoch 76/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7745 - accuracy: 0.6809\n","Epoch 77/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7728 - accuracy: 0.6809\n","Epoch 78/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7718 - accuracy: 0.7234\n","Epoch 79/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7689 - accuracy: 0.7234\n","Epoch 80/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7738 - accuracy: 0.6809\n","Epoch 81/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7757 - accuracy: 0.7021\n","Epoch 82/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7699 - accuracy: 0.7234\n","Epoch 83/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7671 - accuracy: 0.7021\n","Epoch 84/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7648 - accuracy: 0.7021\n","Epoch 85/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7683 - accuracy: 0.6809\n","Epoch 86/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7645 - accuracy: 0.7021\n","Epoch 87/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7647 - accuracy: 0.7234\n","Epoch 88/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7628 - accuracy: 0.6809\n","Epoch 89/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7599 - accuracy: 0.7234\n","Epoch 90/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7593 - accuracy: 0.7234\n","Epoch 91/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7599 - accuracy: 0.7234\n","Epoch 92/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7559 - accuracy: 0.7234\n","Epoch 93/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7559 - accuracy: 0.7234\n","Epoch 94/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7576 - accuracy: 0.7234\n","Epoch 95/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7552 - accuracy: 0.7234\n","Epoch 96/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7525 - accuracy: 0.6809\n","Epoch 97/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7588 - accuracy: 0.7234\n","Epoch 98/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7506 - accuracy: 0.7234\n","Epoch 99/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7532 - accuracy: 0.6809\n","Epoch 100/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7510 - accuracy: 0.7234\n","Epoch 101/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7482 - accuracy: 0.7234\n","Epoch 102/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7487 - accuracy: 0.7234\n","Epoch 103/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7488 - accuracy: 0.7234\n","Epoch 104/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7450 - accuracy: 0.7234\n","Epoch 105/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7443 - accuracy: 0.7234\n","Epoch 106/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7452 - accuracy: 0.7234\n","Epoch 107/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7479 - accuracy: 0.7234\n","Epoch 108/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7479 - accuracy: 0.7234\n","Epoch 109/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7483 - accuracy: 0.7234\n","Epoch 110/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7442 - accuracy: 0.7234\n","Epoch 111/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7426 - accuracy: 0.7234\n","Epoch 112/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7438 - accuracy: 0.6809\n","Epoch 113/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7408 - accuracy: 0.7234\n","Epoch 114/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7423 - accuracy: 0.6809\n","Epoch 115/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7419 - accuracy: 0.7234\n","Epoch 116/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7405 - accuracy: 0.7234\n","Epoch 117/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.7234\n","Epoch 118/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7234\n","Epoch 119/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.7234\n","Epoch 120/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7343 - accuracy: 0.7234\n","Epoch 121/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7347 - accuracy: 0.7234\n","Epoch 122/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7398 - accuracy: 0.7234\n","Epoch 123/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7309 - accuracy: 0.7234\n","Epoch 124/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7308 - accuracy: 0.7234\n","Epoch 125/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7284 - accuracy: 0.7234\n","Epoch 126/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7306 - accuracy: 0.7234\n","Epoch 127/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7317 - accuracy: 0.7234\n","Epoch 128/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7234\n","Epoch 129/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7309 - accuracy: 0.7234\n","Epoch 130/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7278 - accuracy: 0.7234\n","Epoch 131/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7294 - accuracy: 0.7234\n","Epoch 132/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7233 - accuracy: 0.7234\n","Epoch 133/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7236 - accuracy: 0.7021\n","Epoch 134/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7222 - accuracy: 0.7234\n","Epoch 135/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7196 - accuracy: 0.7234\n","Epoch 136/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7210 - accuracy: 0.7234\n","Epoch 137/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7194 - accuracy: 0.7234\n","Epoch 138/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7208 - accuracy: 0.7234\n","Epoch 139/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7184 - accuracy: 0.7234\n","Epoch 140/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7155 - accuracy: 0.7234\n","Epoch 141/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7187 - accuracy: 0.7234\n","Epoch 142/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7193 - accuracy: 0.6809\n","Epoch 143/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7159 - accuracy: 0.7234\n","Epoch 144/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7140 - accuracy: 0.7234\n","Epoch 145/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7143 - accuracy: 0.7234\n","Epoch 146/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7163 - accuracy: 0.7234\n","Epoch 147/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7161 - accuracy: 0.7234\n","Epoch 148/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7079 - accuracy: 0.7234\n","Epoch 149/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7095 - accuracy: 0.7234\n","Epoch 150/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7042 - accuracy: 0.7234\n","Epoch 151/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7028 - accuracy: 0.7234\n","Epoch 152/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6987 - accuracy: 0.7234\n","Epoch 153/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7004 - accuracy: 0.7234\n","Epoch 154/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6966 - accuracy: 0.7234\n","Epoch 155/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6908 - accuracy: 0.7234\n","Epoch 156/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.6900 - accuracy: 0.7234\n","Epoch 157/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6896 - accuracy: 0.7234\n","Epoch 158/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.6840 - accuracy: 0.7234\n","Epoch 159/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6850 - accuracy: 0.7234\n","Epoch 160/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.6815 - accuracy: 0.7234\n","Epoch 161/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.6788 - accuracy: 0.7234\n","Epoch 162/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6805 - accuracy: 0.7234\n","Epoch 163/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.7234\n","Epoch 164/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.6765 - accuracy: 0.7234\n","Epoch 165/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6787 - accuracy: 0.7234\n","Epoch 166/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6792 - accuracy: 0.7234\n","Epoch 167/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6710 - accuracy: 0.7234\n","Epoch 168/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6743 - accuracy: 0.7234\n","Epoch 169/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.6671 - accuracy: 0.7234\n","Epoch 170/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6653 - accuracy: 0.7234\n","Epoch 171/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.7234\n","Epoch 172/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6669 - accuracy: 0.7234\n","Epoch 173/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6616 - accuracy: 0.7234\n","Epoch 174/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.7234\n","Epoch 175/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.7234\n","Epoch 176/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.7234\n","Epoch 177/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.7234\n","Epoch 178/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6534 - accuracy: 0.7234\n","Epoch 179/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.7234\n","Epoch 180/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.7234\n","Epoch 181/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.7234\n","Epoch 182/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6594 - accuracy: 0.7234\n","Epoch 183/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.6479 - accuracy: 0.7234\n","Epoch 184/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.6472 - accuracy: 0.7234\n","Epoch 185/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.7234\n","Epoch 186/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6488 - accuracy: 0.7234\n","Epoch 187/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.7234\n","Epoch 188/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6434 - accuracy: 0.7234\n","Epoch 189/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.7234\n","Epoch 190/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6434 - accuracy: 0.7234\n","Epoch 191/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6386 - accuracy: 0.7234\n","Epoch 192/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.6375 - accuracy: 0.7234\n","Epoch 193/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.7234\n","Epoch 194/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.7234\n","Epoch 195/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.7234\n","Epoch 196/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.7234\n","Epoch 197/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.7234\n","Epoch 198/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.7234\n","Epoch 199/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7234\n","Epoch 200/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.7234\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fe32c25ac20>"]},"metadata":{},"execution_count":18}],"source":["ann.fit(X_train, y_train, batch_size = 5, epochs = 200)"]},{"cell_type":"markdown","metadata":{"id":"tJj5k2MxZga3"},"source":["## Part 4 - Making the predictions and evaluating the model"]},{"cell_type":"markdown","metadata":{"id":"u7yx47jPZt11"},"source":["### Predicting the Test set results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nIyEeQdRZwgs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689498234451,"user_tz":-330,"elapsed":11,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"72fc5df8-57db-4010-f074-c7c0d0a9e34c"},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 162ms/step\n","2/2 [==============================] - 0s 4ms/step\n"]}],"source":["ytest_pred = ann.predict(X_test)\n","ytrain_pred = ann.predict(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Up3Id9FamJCh"},"outputs":[],"source":["y_test_predRounded= []\n","y_test_predEncoded = []\n","ytrain_pred= []\n","ytrain_predRoundeded = []\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hn9vPnXaRRZE"},"outputs":[],"source":["def round(predicted,rounded):\n","  for i in range(len(predicted)):\n","    if predicted[i,0] >  predicted[i,1] and predicted[i,0] >  predicted[i,2]:\n","      rounded.append([1.,0.,0.])\n","    elif predicted[i,1] >  predicted[i,0] and predicted[i,1] >  predicted[i,2]:\n","      rounded.append([0.,1.,0.])\n","    elif predicted[i,2] >  predicted[i,0] and predicted[i,2] >  predicted[i,1]:\n","      rounded.append([0.,0.,1.])\n","    else:\n","      rounded.append([0.,0.,1.])\n","\n","def encode(predicted,encoded):\n","  for i in range(len(predicted)):\n","    if predicted[i,0] >  predicted[i,1] and predicted[i,0] >  predicted[i,2]:\n","      encoded.append(['D'])\n","    elif predicted[i,1] >  predicted[i,0] and predicted[i,1] >  predicted[i,2]:\n","      encoded.append(['M'])\n","    elif predicted[i,2] >  predicted[i,0] and predicted[i,2] >  predicted[i,1]:\n","      encoded.append(['N'])\n","    else:\n","      encoded.append(['N'])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c9-iXheDqeYQ"},"outputs":[],"source":["round(ytest_pred,y_test_predRounded)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xKiFnOVEkVLN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689498235169,"user_tz":-330,"elapsed":7,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"357dbd51-6f54-46e0-efb6-cc4320c12c60"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.3333333333333333"]},"metadata":{},"execution_count":23}],"source":["from sklearn.metrics import accuracy_score\n","accuracy_score(y_test, y_test_predRounded)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aIA9wlFu1Szx","colab":{"base_uri":"https://localhost:8080/","height":328},"executionInfo":{"status":"error","timestamp":1689498235169,"user_tz":-330,"elapsed":6,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"c7ee8e57-fd88-4570-809d-7e44577d14f9"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-fb6ac084c9a5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_predRounded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'wighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.66666667\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m        \u001b[0;34m,\u001b[0m \u001b[0;36m0.66666667\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \"\"\"\n\u001b[0;32m-> 1146\u001b[0;31m     return fbeta_score(\n\u001b[0m\u001b[1;32m   1147\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1285\u001b[0m     \"\"\"\n\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   1288\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1370\u001b[0m     \u001b[0maverage_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"micro\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"macro\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"weighted\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"samples\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maverage_options\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average has to be one of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: average has to be one of (None, 'micro', 'macro', 'weighted', 'samples')"]}],"source":["from sklearn.metrics import f1_score\n","f1_score(y_test, y_test_predRounded, average='wighted')"]}],"metadata":{"colab":{"provenance":[{"file_id":"1C29XcV-ykBUe9MVmlwPBBbh4IGtA-p9y","timestamp":1634686939845}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}