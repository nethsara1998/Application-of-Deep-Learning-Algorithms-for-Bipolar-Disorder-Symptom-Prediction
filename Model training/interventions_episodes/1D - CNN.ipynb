{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1vUT9ldxADHLHKt7G6Kzl03eIfwjszKfi","timestamp":1652437669035},{"file_id":"1C29XcV-ykBUe9MVmlwPBBbh4IGtA-p9y","timestamp":1634686939845}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"lP6JLo1tGNBg"},"source":["# Artificial Neural Network"]},{"cell_type":"markdown","metadata":{"id":"gWZyYmS_UE_L"},"source":["### Importing the libraries"]},{"cell_type":"code","metadata":{"id":"MxkJoQBkUIHC"},"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.metrics import classification_report"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZaTwK7ojXr2F","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1689497888007,"user_tz":-330,"elapsed":14,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"1784c483-4662-4866-b96f-deeff54d71b5"},"source":["tf.__version__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.12.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"1E0Q3aoKUCRX"},"source":["## Part 1 - Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"cKWAkFVGUU0Z"},"source":["### Importing the dataset"]},{"cell_type":"code","metadata":{"id":"MXUkhkMfU4wq"},"source":["dataset = pd.read_csv('interventions_episodes.csv')\n","X = dataset.iloc[:, 1:-1].values\n","y = dataset.iloc[:, -1].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VYP9cQTWbzuI","executionInfo":{"status":"ok","timestamp":1689497888008,"user_tz":-330,"elapsed":13,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"808eadeb-c76d-42ae-e8ad-905b9961adb8"},"source":["print(X)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[80  5]\n"," [80  5]\n"," [80  1]\n"," [60  3]\n"," [70  5]\n"," [80  3]\n"," [85  2]\n"," [80  3]\n"," [90  3]\n"," [85  3]\n"," [75  4]\n"," [75  4]\n"," [90  5]\n"," [90  3]\n"," [80  6]\n"," [50  7]\n"," [80  6]\n"," [60  5]\n"," [85  2]\n"," [75  5]\n"," [85  1]\n"," [65  5]\n"," [85  5]\n"," [90  2]\n"," [70  5]\n"," [90  3]\n"," [70  5]\n"," [80  5]\n"," [70  2]\n"," [85  2]\n"," [95  2]\n"," [95  2]\n"," [95  4]\n"," [95  4]\n"," [85  2]\n"," [90  6]\n"," [90  3]\n"," [75  4]\n"," [70  5]\n"," [70  5]\n"," [85  2]\n"," [80  2]\n"," [90  3]\n"," [80  3]\n"," [90  2]\n"," [85  3]\n"," [90  4]\n"," [80  6]\n"," [95  2]\n"," [85  3]\n"," [85  3]\n"," [85  3]\n"," [85  6]\n"," [90  3]\n"," [80  6]\n"," [90  3]\n"," [90  4]\n"," [80  3]\n"," [90  4]]\n"]}]},{"cell_type":"code","metadata":{"id":"38vKGE6Nb2RR","executionInfo":{"status":"ok","timestamp":1689497888008,"user_tz":-330,"elapsed":11,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d9260983-2b65-467d-a02c-d7060c6dee0c"},"source":["print(y)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['N' 'N' 'N' 'M' 'N' 'M' 'N' 'N' 'M' 'N' 'N' 'N' 'N' 'N' 'D' 'D' 'D' 'D'\n"," 'N' 'D' 'N' 'N' 'N' 'N' 'D' 'N' 'D' 'N' 'M' 'M' 'N' 'N' 'N' 'N' 'D' 'M'\n"," 'D' 'M' 'D' 'D' 'M' 'M' 'N' 'M' 'N' 'D' 'N' 'M' 'D' 'D' 'N' 'N' 'N' 'D'\n"," 'N' 'D' 'D' 'N' 'N']\n"]}]},{"cell_type":"markdown","metadata":{"id":"N6bQ0UgSU-NJ"},"source":["### Encoding categorical data"]},{"cell_type":"code","metadata":{"id":"PxVKWXxLbczC"},"source":["y= np.array(y.reshape(len(y),1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-M1KboxFb6OO"},"source":["#print(y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CUxGZezpbMcb"},"source":["One Hot Encoding the Y column"]},{"cell_type":"code","metadata":{"id":"AMXC8-KMVirw"},"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])])\n","y = np.array(ct.fit_transform(y))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZcxwEon-b8nV","executionInfo":{"status":"ok","timestamp":1689497888009,"user_tz":-330,"elapsed":10,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a04b31ab-ce89-41a2-db01-46a4bf79fcde"},"source":["y"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [0., 0., 1.]])"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"vHol938cW8zd"},"source":["### Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","metadata":{"id":"Z-TDt0Y_XEfc"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wJo5uPxAdFi5","executionInfo":{"status":"ok","timestamp":1689497888375,"user_tz":-330,"elapsed":374,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ee58ea76-794e-49f0-ef0d-8d4b562f2594"},"source":["X_train"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[95,  2],\n","       [80,  2],\n","       [95,  4],\n","       [90,  3],\n","       [95,  2],\n","       [80,  3],\n","       [80,  6],\n","       [95,  4],\n","       [85,  3],\n","       [85,  2],\n","       [75,  4],\n","       [90,  4],\n","       [85,  2],\n","       [90,  3],\n","       [80,  5],\n","       [50,  7],\n","       [80,  3],\n","       [95,  2],\n","       [80,  6],\n","       [85,  3],\n","       [85,  1],\n","       [85,  3],\n","       [90,  3],\n","       [90,  3],\n","       [90,  3],\n","       [60,  5],\n","       [90,  4],\n","       [80,  3],\n","       [85,  6],\n","       [70,  5],\n","       [80,  5],\n","       [90,  5],\n","       [85,  3],\n","       [70,  5],\n","       [85,  2],\n","       [90,  2],\n","       [90,  3],\n","       [65,  5],\n","       [75,  5],\n","       [85,  3],\n","       [70,  5],\n","       [80,  6],\n","       [60,  3],\n","       [80,  5],\n","       [90,  3],\n","       [80,  6],\n","       [90,  2]])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["print(X_train.shape)\n","print(X_train[0].shape)\n","print(X_train[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U6uqvK4GL5R7","executionInfo":{"status":"ok","timestamp":1689497888377,"user_tz":-330,"elapsed":8,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"c5a3e5cc-4058-45bf-e879-23d50abf0f84"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(47, 2)\n","(2,)\n","[95  2]\n"]}]},{"cell_type":"markdown","metadata":{"id":"RE_FcHyfV3TQ"},"source":["### Feature Scaling"]},{"cell_type":"code","metadata":{"id":"ViCrE00rV8Sk"},"source":["from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_size = X_train.shape[0] # number of samples in train set\n","time_steps  = X_train.shape[1] # number of features in train set\n","input_dimension = 1               # each feature is represented by 1 number\n","\n","X_train_reshaped = X_train.reshape(sample_size,time_steps,input_dimension)"],"metadata":{"id":"jz1JeF8cM-Dv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test_reshaped = X_test.reshape(X_test.shape[0],X_test.shape[1],1)"],"metadata":{"id":"IOIwBiULNl0n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-zfEzkRVXIwF"},"source":["## Part 2 - Building the 1D-CNN"]},{"cell_type":"code","source":["n_timesteps = X_train_reshaped.shape[1]\n","n_features  = X_train_reshaped.shape[2]\n","model = tf.keras.Sequential()\n","model.add(tf.keras.layers.Input(shape=(n_timesteps,n_features)))\n","model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=1, activation='relu'))\n","model.add(tf.keras.layers.Conv1D(filters=32, kernel_size=1, activation='relu'))\n","model.add(tf.keras.layers.Conv1D(filters=16, kernel_size=1, activation='relu'))\n","model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(96, activation='relu'))\n","model.add(tf.keras.layers.Dense(16, activation='relu'))\n","model.add(tf.keras.layers.Dense(3, activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"],"metadata":{"id":"56bBT6nf99Lr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JT4u2S1_Y4WG"},"source":["## Part 3 - Training the ANN"]},{"cell_type":"code","metadata":{"id":"fG3RrwDXZEaS","executionInfo":{"status":"ok","timestamp":1689497910625,"user_tz":-330,"elapsed":22253,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"82da3f8a-433f-40d0-c290-9d54c2306849"},"source":["model.fit(X_train_reshaped, y_train, batch_size = 5, epochs = 200)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","10/10 [==============================] - 2s 3ms/step - loss: 1.0916 - accuracy: 0.4894\n","Epoch 2/200\n","10/10 [==============================] - 0s 2ms/step - loss: 1.0681 - accuracy: 0.5319\n","Epoch 3/200\n","10/10 [==============================] - 0s 2ms/step - loss: 1.0468 - accuracy: 0.5319\n","Epoch 4/200\n","10/10 [==============================] - 0s 3ms/step - loss: 1.0214 - accuracy: 0.5319\n","Epoch 5/200\n","10/10 [==============================] - 0s 3ms/step - loss: 1.0024 - accuracy: 0.5319\n","Epoch 6/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.9771 - accuracy: 0.5319\n","Epoch 7/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.9692 - accuracy: 0.5319\n","Epoch 8/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.9581 - accuracy: 0.5319\n","Epoch 9/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.9537 - accuracy: 0.5319\n","Epoch 10/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.9422 - accuracy: 0.5319\n","Epoch 11/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.9382 - accuracy: 0.5319\n","Epoch 12/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.9306 - accuracy: 0.5319\n","Epoch 13/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.9234 - accuracy: 0.5319\n","Epoch 14/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.9146 - accuracy: 0.5532\n","Epoch 15/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.9097 - accuracy: 0.5532\n","Epoch 16/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.9070 - accuracy: 0.5745\n","Epoch 17/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.9033 - accuracy: 0.5957\n","Epoch 18/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.8967 - accuracy: 0.5745\n","Epoch 19/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.8856 - accuracy: 0.5745\n","Epoch 20/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.8785 - accuracy: 0.5745\n","Epoch 21/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8742 - accuracy: 0.5745\n","Epoch 22/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8774 - accuracy: 0.5745\n","Epoch 23/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.8706 - accuracy: 0.5745\n","Epoch 24/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.8595 - accuracy: 0.6170\n","Epoch 25/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.9129 - accuracy: 0.5319\n","Epoch 26/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8663 - accuracy: 0.5532\n","Epoch 27/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.8746 - accuracy: 0.5957\n","Epoch 28/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.8564 - accuracy: 0.5532\n","Epoch 29/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8710 - accuracy: 0.4894\n","Epoch 30/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.8552 - accuracy: 0.5319\n","Epoch 31/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.8553 - accuracy: 0.5745\n","Epoch 32/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.8450 - accuracy: 0.5745\n","Epoch 33/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.8383 - accuracy: 0.5532\n","Epoch 34/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.8377 - accuracy: 0.5745\n","Epoch 35/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.8410 - accuracy: 0.6170\n","Epoch 36/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.8437 - accuracy: 0.5532\n","Epoch 37/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.8309 - accuracy: 0.5532\n","Epoch 38/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8307 - accuracy: 0.5745\n","Epoch 39/200\n","10/10 [==============================] - 0s 9ms/step - loss: 0.8365 - accuracy: 0.5957\n","Epoch 40/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8290 - accuracy: 0.5319\n","Epoch 41/200\n","10/10 [==============================] - 0s 8ms/step - loss: 0.8320 - accuracy: 0.5957\n","Epoch 42/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.8286 - accuracy: 0.5745\n","Epoch 43/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.8384 - accuracy: 0.5745\n","Epoch 44/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8324 - accuracy: 0.5745\n","Epoch 45/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.8199 - accuracy: 0.5532\n","Epoch 46/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.8217 - accuracy: 0.5532\n","Epoch 47/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.8148 - accuracy: 0.5745\n","Epoch 48/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.8129 - accuracy: 0.5957\n","Epoch 49/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.8322 - accuracy: 0.5745\n","Epoch 50/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7988 - accuracy: 0.5745\n","Epoch 51/200\n","10/10 [==============================] - 0s 10ms/step - loss: 0.8173 - accuracy: 0.5319\n","Epoch 52/200\n","10/10 [==============================] - 0s 8ms/step - loss: 0.8162 - accuracy: 0.5745\n","Epoch 53/200\n","10/10 [==============================] - 0s 9ms/step - loss: 0.8130 - accuracy: 0.5532\n","Epoch 54/200\n","10/10 [==============================] - 0s 6ms/step - loss: 0.8183 - accuracy: 0.5745\n","Epoch 55/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.8004 - accuracy: 0.5745\n","Epoch 56/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.8037 - accuracy: 0.5745\n","Epoch 57/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.8080 - accuracy: 0.5745\n","Epoch 58/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7998 - accuracy: 0.5957\n","Epoch 59/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7986 - accuracy: 0.5745\n","Epoch 60/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7962 - accuracy: 0.5745\n","Epoch 61/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.8010 - accuracy: 0.6170\n","Epoch 62/200\n","10/10 [==============================] - 0s 8ms/step - loss: 0.7913 - accuracy: 0.5745\n","Epoch 63/200\n","10/10 [==============================] - 0s 6ms/step - loss: 0.7919 - accuracy: 0.5745\n","Epoch 64/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7915 - accuracy: 0.5745\n","Epoch 65/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.8126 - accuracy: 0.5745\n","Epoch 66/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7993 - accuracy: 0.5745\n","Epoch 67/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.8056 - accuracy: 0.5957\n","Epoch 68/200\n","10/10 [==============================] - 0s 8ms/step - loss: 0.8212 - accuracy: 0.5745\n","Epoch 69/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7969 - accuracy: 0.5319\n","Epoch 70/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7986 - accuracy: 0.5532\n","Epoch 71/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.8003 - accuracy: 0.5532\n","Epoch 72/200\n","10/10 [==============================] - 0s 6ms/step - loss: 0.7858 - accuracy: 0.5745\n","Epoch 73/200\n","10/10 [==============================] - 0s 6ms/step - loss: 0.7941 - accuracy: 0.6170\n","Epoch 74/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7926 - accuracy: 0.5957\n","Epoch 75/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7874 - accuracy: 0.5745\n","Epoch 76/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7852 - accuracy: 0.5745\n","Epoch 77/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7961 - accuracy: 0.6170\n","Epoch 78/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7968 - accuracy: 0.5745\n","Epoch 79/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.8070 - accuracy: 0.5532\n","Epoch 80/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7810 - accuracy: 0.5745\n","Epoch 81/200\n","10/10 [==============================] - 0s 7ms/step - loss: 0.7851 - accuracy: 0.6383\n","Epoch 82/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7953 - accuracy: 0.5532\n","Epoch 83/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7815 - accuracy: 0.5957\n","Epoch 84/200\n","10/10 [==============================] - 0s 7ms/step - loss: 0.8007 - accuracy: 0.5745\n","Epoch 85/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.8365 - accuracy: 0.5745\n","Epoch 86/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.8035 - accuracy: 0.5745\n","Epoch 87/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7950 - accuracy: 0.5745\n","Epoch 88/200\n","10/10 [==============================] - 0s 6ms/step - loss: 0.7923 - accuracy: 0.5745\n","Epoch 89/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7825 - accuracy: 0.5745\n","Epoch 90/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7794 - accuracy: 0.5957\n","Epoch 91/200\n","10/10 [==============================] - 0s 7ms/step - loss: 0.7788 - accuracy: 0.5957\n","Epoch 92/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7832 - accuracy: 0.5957\n","Epoch 93/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7726 - accuracy: 0.5957\n","Epoch 94/200\n","10/10 [==============================] - 0s 7ms/step - loss: 0.7803 - accuracy: 0.5745\n","Epoch 95/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7727 - accuracy: 0.5957\n","Epoch 96/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7726 - accuracy: 0.5957\n","Epoch 97/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7736 - accuracy: 0.5957\n","Epoch 98/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7706 - accuracy: 0.5957\n","Epoch 99/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7685 - accuracy: 0.5957\n","Epoch 100/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7731 - accuracy: 0.5957\n","Epoch 101/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7666 - accuracy: 0.5957\n","Epoch 102/200\n","10/10 [==============================] - 0s 6ms/step - loss: 0.7811 - accuracy: 0.5957\n","Epoch 103/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7780 - accuracy: 0.5957\n","Epoch 104/200\n","10/10 [==============================] - 0s 7ms/step - loss: 0.7716 - accuracy: 0.5957\n","Epoch 105/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7640 - accuracy: 0.5957\n","Epoch 106/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7720 - accuracy: 0.5745\n","Epoch 107/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7573 - accuracy: 0.5745\n","Epoch 108/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7647 - accuracy: 0.5745\n","Epoch 109/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7709 - accuracy: 0.5745\n","Epoch 110/200\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7645 - accuracy: 0.5957\n","Epoch 111/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7683 - accuracy: 0.5957\n","Epoch 112/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7591 - accuracy: 0.5745\n","Epoch 113/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7584 - accuracy: 0.5532\n","Epoch 114/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7578 - accuracy: 0.5745\n","Epoch 115/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7588 - accuracy: 0.5957\n","Epoch 116/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7714 - accuracy: 0.5745\n","Epoch 117/200\n","10/10 [==============================] - 0s 8ms/step - loss: 0.7644 - accuracy: 0.5745\n","Epoch 118/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7564 - accuracy: 0.5745\n","Epoch 119/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7542 - accuracy: 0.5957\n","Epoch 120/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7598 - accuracy: 0.5957\n","Epoch 121/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7588 - accuracy: 0.5745\n","Epoch 122/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7521 - accuracy: 0.5957\n","Epoch 123/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7593 - accuracy: 0.5532\n","Epoch 124/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7533 - accuracy: 0.5745\n","Epoch 125/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7539 - accuracy: 0.5957\n","Epoch 126/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7448 - accuracy: 0.5745\n","Epoch 127/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7599 - accuracy: 0.5745\n","Epoch 128/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7471 - accuracy: 0.5957\n","Epoch 129/200\n","10/10 [==============================] - 0s 7ms/step - loss: 0.7422 - accuracy: 0.5957\n","Epoch 130/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.5745\n","Epoch 131/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7466 - accuracy: 0.5957\n","Epoch 132/200\n","10/10 [==============================] - 0s 8ms/step - loss: 0.7424 - accuracy: 0.5745\n","Epoch 133/200\n","10/10 [==============================] - 0s 6ms/step - loss: 0.7397 - accuracy: 0.5745\n","Epoch 134/200\n","10/10 [==============================] - 0s 8ms/step - loss: 0.7414 - accuracy: 0.5745\n","Epoch 135/200\n","10/10 [==============================] - 0s 7ms/step - loss: 0.7427 - accuracy: 0.5957\n","Epoch 136/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7448 - accuracy: 0.5745\n","Epoch 137/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7361 - accuracy: 0.5745\n","Epoch 138/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7346 - accuracy: 0.5957\n","Epoch 139/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.5745\n","Epoch 140/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7367 - accuracy: 0.5745\n","Epoch 141/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7423 - accuracy: 0.6170\n","Epoch 142/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7415 - accuracy: 0.5957\n","Epoch 143/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7348 - accuracy: 0.5745\n","Epoch 144/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7724 - accuracy: 0.5745\n","Epoch 145/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7408 - accuracy: 0.5957\n","Epoch 146/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7504 - accuracy: 0.5957\n","Epoch 147/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7520 - accuracy: 0.5745\n","Epoch 148/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7387 - accuracy: 0.5745\n","Epoch 149/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7363 - accuracy: 0.5745\n","Epoch 150/200\n","10/10 [==============================] - 0s 8ms/step - loss: 0.7312 - accuracy: 0.5745\n","Epoch 151/200\n","10/10 [==============================] - 0s 6ms/step - loss: 0.7427 - accuracy: 0.5745\n","Epoch 152/200\n","10/10 [==============================] - 0s 8ms/step - loss: 0.7360 - accuracy: 0.5957\n","Epoch 153/200\n","10/10 [==============================] - 0s 8ms/step - loss: 0.7386 - accuracy: 0.5745\n","Epoch 154/200\n","10/10 [==============================] - 0s 7ms/step - loss: 0.7589 - accuracy: 0.5957\n","Epoch 155/200\n","10/10 [==============================] - 0s 8ms/step - loss: 0.7293 - accuracy: 0.6170\n","Epoch 156/200\n","10/10 [==============================] - 0s 9ms/step - loss: 0.7479 - accuracy: 0.5957\n","Epoch 157/200\n","10/10 [==============================] - 0s 7ms/step - loss: 0.7422 - accuracy: 0.6170\n","Epoch 158/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7248 - accuracy: 0.6170\n","Epoch 159/200\n","10/10 [==============================] - 0s 3ms/step - loss: 0.7254 - accuracy: 0.5957\n","Epoch 160/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7216 - accuracy: 0.5957\n","Epoch 161/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7204 - accuracy: 0.5957\n","Epoch 162/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7241 - accuracy: 0.5957\n","Epoch 163/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7302 - accuracy: 0.5532\n","Epoch 164/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7303 - accuracy: 0.5745\n","Epoch 165/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7324 - accuracy: 0.6383\n","Epoch 166/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7243 - accuracy: 0.6383\n","Epoch 167/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7401 - accuracy: 0.6170\n","Epoch 168/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7393 - accuracy: 0.5957\n","Epoch 169/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7179 - accuracy: 0.5957\n","Epoch 170/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7259 - accuracy: 0.5745\n","Epoch 171/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7157 - accuracy: 0.6170\n","Epoch 172/200\n","10/10 [==============================] - 0s 6ms/step - loss: 0.7230 - accuracy: 0.6383\n","Epoch 173/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7131 - accuracy: 0.6383\n","Epoch 174/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7223 - accuracy: 0.5745\n","Epoch 175/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7252 - accuracy: 0.6383\n","Epoch 176/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7281 - accuracy: 0.6170\n","Epoch 177/200\n","10/10 [==============================] - 0s 7ms/step - loss: 0.7245 - accuracy: 0.5532\n","Epoch 178/200\n","10/10 [==============================] - 0s 7ms/step - loss: 0.7190 - accuracy: 0.6383\n","Epoch 179/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7139 - accuracy: 0.6170\n","Epoch 180/200\n","10/10 [==============================] - 0s 7ms/step - loss: 0.7119 - accuracy: 0.6170\n","Epoch 181/200\n","10/10 [==============================] - 0s 9ms/step - loss: 0.7349 - accuracy: 0.6170\n","Epoch 182/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7174 - accuracy: 0.6383\n","Epoch 183/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7128 - accuracy: 0.5745\n","Epoch 184/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7260 - accuracy: 0.5745\n","Epoch 185/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7177 - accuracy: 0.6170\n","Epoch 186/200\n","10/10 [==============================] - 0s 6ms/step - loss: 0.7157 - accuracy: 0.6383\n","Epoch 187/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7239 - accuracy: 0.6170\n","Epoch 188/200\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7149 - accuracy: 0.6170\n","Epoch 189/200\n","10/10 [==============================] - 0s 6ms/step - loss: 0.7060 - accuracy: 0.6170\n","Epoch 190/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7078 - accuracy: 0.6170\n","Epoch 191/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7017 - accuracy: 0.6170\n","Epoch 192/200\n","10/10 [==============================] - 0s 9ms/step - loss: 0.7031 - accuracy: 0.6170\n","Epoch 193/200\n","10/10 [==============================] - 0s 7ms/step - loss: 0.7058 - accuracy: 0.6170\n","Epoch 194/200\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7038 - accuracy: 0.6383\n","Epoch 195/200\n","10/10 [==============================] - 0s 7ms/step - loss: 0.7012 - accuracy: 0.6383\n","Epoch 196/200\n","10/10 [==============================] - 0s 9ms/step - loss: 0.7052 - accuracy: 0.6170\n","Epoch 197/200\n","10/10 [==============================] - 0s 8ms/step - loss: 0.7049 - accuracy: 0.6170\n","Epoch 198/200\n","10/10 [==============================] - 0s 7ms/step - loss: 0.6971 - accuracy: 0.5957\n","Epoch 199/200\n","10/10 [==============================] - 0s 6ms/step - loss: 0.7003 - accuracy: 0.5957\n","Epoch 200/200\n","10/10 [==============================] - 0s 11ms/step - loss: 0.7029 - accuracy: 0.5957\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7833383591e0>"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"tJj5k2MxZga3"},"source":["## Part 4 - Making the predictions and evaluating the model"]},{"cell_type":"code","metadata":{"id":"nHZ-LKv_ZRb3","executionInfo":{"status":"ok","timestamp":1689497910626,"user_tz":-330,"elapsed":13,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"58348514-18cd-40f0-cbfc-1663e1f2c84b"},"source":["model.evaluate(X_test_reshaped,y_test,batch_size = 5)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3/3 [==============================] - 0s 5ms/step - loss: 1.4155 - accuracy: 0.5000\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.4154638051986694, 0.5]"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"u7yx47jPZt11"},"source":["### Predicting the Test set results"]},{"cell_type":"code","metadata":{"id":"nIyEeQdRZwgs","executionInfo":{"status":"ok","timestamp":1689497911186,"user_tz":-330,"elapsed":571,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ac58f3cd-79bb-46c6-e470-114a63222725"},"source":["y_pred = model.predict(X_test_reshaped)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 126ms/step\n"]}]},{"cell_type":"code","metadata":{"id":"sn8b7_pKdsAX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689497911186,"user_tz":-330,"elapsed":7,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"61dfd1ce-0302-477a-be8c-24829db648de"},"source":["y_pred"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[5.4420894e-01, 7.5655174e-03, 4.4822571e-01],\n","       [3.9451152e-02, 8.5344128e-03, 9.5201451e-01],\n","       [1.5133561e-02, 3.9745447e-01, 5.8741194e-01],\n","       [7.5704622e-05, 8.7018156e-01, 1.2974273e-01],\n","       [3.1175377e-02, 2.3388486e-01, 7.3493981e-01],\n","       [5.8036267e-06, 9.3160504e-01, 6.8389177e-02],\n","       [9.3908291e-03, 2.3746613e-01, 7.5314295e-01],\n","       [1.3992447e-01, 3.5845518e-02, 8.2422996e-01],\n","       [9.3908291e-03, 2.3746614e-01, 7.5314301e-01],\n","       [1.1299058e-01, 2.7829260e-02, 8.5918015e-01],\n","       [5.4420888e-01, 7.5655165e-03, 4.4822565e-01],\n","       [3.1175375e-02, 2.3388486e-01, 7.3493981e-01]], dtype=float32)"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"Up3Id9FamJCh"},"source":["y_predRounded= []\n","y_predEncoded = []\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JE2afjq4WwbT"},"source":["def round(predicted,rounded):\n","  for i in range(len(predicted)):\n","    if predicted[i,0] >  predicted[i,1] and predicted[i,0] >  predicted[i,2]:\n","      rounded.append([1.,0.,0.])\n","    elif predicted[i,1] >  predicted[i,0] and predicted[i,1] >  predicted[i,2]:\n","      rounded.append([0.,1.,0.])\n","    elif predicted[i,2] >  predicted[i,0] and predicted[i,2] >  predicted[i,1]:\n","      rounded.append([0.,0.,1.])\n","    else:\n","      rounded.append([0.,0.,1.])\n","\n","def encode(predicted,encoded):\n","  for i in range(len(predicted)):\n","    if predicted[i,0] >  predicted[i,1] and predicted[i,0] >  predicted[i,2]:\n","      encoded.append(['D'])\n","    elif predicted[i,1] >  predicted[i,0] and predicted[i,1] >  predicted[i,2]:\n","      encoded.append(['M'])\n","    elif predicted[i,2] >  predicted[i,0] and predicted[i,2] >  predicted[i,1]:\n","      encoded.append(['N'])\n","    else:\n","      encoded.append(['N'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["round(y_pred,y_predRounded)"],"metadata":{"id":"KME6Vr1kUohN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","accuracy_score(y_test, y_predRounded)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y1J470oFJbA1","executionInfo":{"status":"ok","timestamp":1689497911187,"user_tz":-330,"elapsed":6,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"7be78ae2-5347-41c0-bacb-4f28134e4cd9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","f1_score(y_test, y_predRounded, average='weighted')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DGD7g3jMJhAN","executionInfo":{"status":"ok","timestamp":1689497936179,"user_tz":-330,"elapsed":377,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"3ccbaef1-280e-4147-bc45-e5d4837d7eec"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4801587301587302"]},"metadata":{},"execution_count":26}]}]}